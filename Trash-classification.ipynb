{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Smart system based on Deep Convolutional Neural Networks to classify Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras import models\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for reproducibility\n",
    "np.random.seed(78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions\n",
    "img_rows, img_cols, img_chans = 384, 512, 3\n",
    "input_shape = (img_rows, img_cols, img_chans)\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 2000\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    #Loading the VGG model\n",
    "    vgg_conv = VGG16(weights='imagenet', include_top=False,  input_shape=input_shape)\n",
    "    \n",
    "    for i in range(8):\n",
    "        #removing the last layers  \n",
    "        vgg_conv.layers.pop() \n",
    "    \n",
    "    \n",
    "    # Freezing all layers\n",
    "    for layer in vgg_conv.layers[:]:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    # Building Deep learning model\n",
    "    model = models.Sequential()\n",
    "     \n",
    "    # Adding the vgg model\n",
    "    model.add(vgg_conv)\n",
    "     \n",
    "    # Adding new layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(350, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(350, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "     \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adagrad(lr=1e-5, decay=1e-6), metrics=['accuracy'])\n",
    "    \n",
    "    \"\"\"\n",
    "    files = glob('Model2**')\n",
    "    print(files)\n",
    "    list_models=[]\n",
    "    for  model_ in files:\n",
    "        list_models.append(float(model_[:-5].split('=')[1]))\n",
    "        \n",
    "    index = np.argmin(list_models)\n",
    "    load_model = files[index]\n",
    "    print(load_model)\n",
    "\n",
    "    if load_model is not None:\n",
    "            model.load_weights(load_model)\n",
    "            print(\"weights are loaded\")\n",
    "    else:\n",
    "            print(\"weights are None\")\n",
    "    \"\"\"       \n",
    "    \n",
    "    call =  [                  \n",
    "                                    EarlyStopping(monitor='val_loss',  patience=20, verbose=1,  mode='auto'),\n",
    "            ]\n",
    "    \n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "        # This will do preprocessing and realtime data augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset   \n",
    "        samplewise_center=False,  # set each sample mean to 0   \n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset   \n",
    "        samplewise_std_normalization=False,  # divide each input by its std  \n",
    "        zca_whitening=False,  # apply ZCA whitening     \n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)  <<1    0 => 30\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,  # set range for random shear  <<3<<4  0 => 0.1 => 0.2\n",
    "        zoom_range=0.3,  # set range for random zoom    <<1<<2<<3   0 => 0.1 => 0.2 =>0.3 \n",
    "        channel_shift_range=0.2,  # set range for random channel shifts     <<5<<6   0.=>0.1=>0.2\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"     \n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images    <<1    false => True\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,   \n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "    \n",
    "        print(\"steps_per_epoch (nbr of samples per epoch):\", int(len(x_train)/batch_size))\n",
    "        # Fit the model on the batches generated by datagen.flow().\n",
    "        history = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),steps_per_epoch = 800,\n",
    "                            epochs=2000,\n",
    "                            validation_data=(x_test, y_test),\n",
    "                            workers=10, callbacks = call)\n",
    "        \n",
    "        weights = '{}.hdf5'.format('Model3_adagrad_'+'val_acc:'+str(round(history.history['val_acc'][-1],3))+' val_loss='+str(round(history.history['val_loss'][-1],3)))\n",
    "        model.save_weights(weights)\n",
    "        print ('Model saved.')\n",
    "        \n",
    "        score = model.evaluate(x_test, y_test,batch_size=10, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        acc = history.history['acc']\n",
    "        val_acc = history.history['val_acc']\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "\n",
    "        epoch = range(len(acc))\n",
    "\n",
    "        plt.plot(epoch, acc, 'b', label='Training acc')\n",
    "        plt.plot(epoch, val_acc, 'r', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.legend()\n",
    "        plt.figure()\n",
    "\n",
    "        plt.plot(epoch, loss, 'b', label='Training loss')\n",
    "        plt.plot(epoch, val_loss, 'r', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test):\n",
    "    \n",
    "    image = np.expand_dims((x_test[58] - np.mean(x_test))/ np.std(x_test), axis=0)\n",
    "\n",
    "    plt.imshow(x_test[58])\n",
    "    plt.show()\n",
    "\n",
    "    out = model.predict(x_test[58])\n",
    "    out = np.argmax(out)\n",
    "\n",
    "    if out == 1:\n",
    "            label = 'plastic'\n",
    "    else:\n",
    "            label = 'glass'\n",
    "\n",
    "    return out, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (688, 384, 512, 3)\n",
      "688 train samples\n",
      "295 test samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/envs/tfenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Using real-time data augmentation.\n",
      "steps_per_epoch (nbr of samples per epoch): 86\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.7033 - acc: 0.5275 - val_loss: 0.6807 - val_acc: 0.5763\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6780 - acc: 0.5737 - val_loss: 0.6638 - val_acc: 0.6102\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6672 - acc: 0.5859 - val_loss: 0.6592 - val_acc: 0.6085\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6566 - acc: 0.6109 - val_loss: 0.6518 - val_acc: 0.6373\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6502 - acc: 0.6219 - val_loss: 0.6451 - val_acc: 0.6458\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6415 - acc: 0.6350 - val_loss: 0.6369 - val_acc: 0.6661\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.6276 - acc: 0.6581 - val_loss: 0.6273 - val_acc: 0.6780\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.6172 - acc: 0.6594 - val_loss: 0.6255 - val_acc: 0.6746\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6310 - acc: 0.6394 - val_loss: 0.6203 - val_acc: 0.6746\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6169 - acc: 0.6663 - val_loss: 0.6172 - val_acc: 0.6729\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6127 - acc: 0.6694 - val_loss: 0.6113 - val_acc: 0.6746\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6121 - acc: 0.6697 - val_loss: 0.6034 - val_acc: 0.6949\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6109 - acc: 0.6719 - val_loss: 0.6011 - val_acc: 0.6898\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.6037 - acc: 0.6819 - val_loss: 0.6010 - val_acc: 0.6831\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.6047 - acc: 0.6750 - val_loss: 0.5947 - val_acc: 0.6898\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5933 - acc: 0.6947 - val_loss: 0.5896 - val_acc: 0.7085\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5963 - acc: 0.6922 - val_loss: 0.5850 - val_acc: 0.7136\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5817 - acc: 0.7078 - val_loss: 0.5841 - val_acc: 0.7068\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5801 - acc: 0.7063 - val_loss: 0.5818 - val_acc: 0.6966\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5819 - acc: 0.7128 - val_loss: 0.5773 - val_acc: 0.7068\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5876 - acc: 0.6994 - val_loss: 0.5757 - val_acc: 0.7051\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5738 - acc: 0.7069 - val_loss: 0.5734 - val_acc: 0.7034\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5718 - acc: 0.7106 - val_loss: 0.5719 - val_acc: 0.7068\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5748 - acc: 0.7019 - val_loss: 0.5676 - val_acc: 0.7102\n",
      "Epoch 25/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5677 - acc: 0.7188 - val_loss: 0.5628 - val_acc: 0.7220\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5694 - acc: 0.7125 - val_loss: 0.5628 - val_acc: 0.7119\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5710 - acc: 0.7094 - val_loss: 0.5620 - val_acc: 0.7169\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5533 - acc: 0.7422 - val_loss: 0.5598 - val_acc: 0.7220\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5515 - acc: 0.7391 - val_loss: 0.5556 - val_acc: 0.7271\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5545 - acc: 0.7241 - val_loss: 0.5549 - val_acc: 0.7271\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5546 - acc: 0.7294 - val_loss: 0.5537 - val_acc: 0.7203\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5479 - acc: 0.7372 - val_loss: 0.5550 - val_acc: 0.7271\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5540 - acc: 0.7266 - val_loss: 0.5482 - val_acc: 0.7407\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5388 - acc: 0.7434 - val_loss: 0.5455 - val_acc: 0.7407\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5428 - acc: 0.7300 - val_loss: 0.5438 - val_acc: 0.7390\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5427 - acc: 0.7447 - val_loss: 0.5437 - val_acc: 0.7322\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5457 - acc: 0.7325 - val_loss: 0.5419 - val_acc: 0.7373\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5460 - acc: 0.7337 - val_loss: 0.5394 - val_acc: 0.7407\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.5352 - acc: 0.7494 - val_loss: 0.5395 - val_acc: 0.7407\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5366 - acc: 0.7375 - val_loss: 0.5378 - val_acc: 0.7441\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5407 - acc: 0.7359 - val_loss: 0.5354 - val_acc: 0.7458\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5354 - acc: 0.7494 - val_loss: 0.5332 - val_acc: 0.7492\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5254 - acc: 0.7647 - val_loss: 0.5337 - val_acc: 0.7492\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5292 - acc: 0.7584 - val_loss: 0.5292 - val_acc: 0.7576\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5126 - acc: 0.7716 - val_loss: 0.5292 - val_acc: 0.7525\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5258 - acc: 0.7516 - val_loss: 0.5257 - val_acc: 0.7627\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.5279 - acc: 0.7581 - val_loss: 0.5223 - val_acc: 0.7661\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5279 - acc: 0.7525 - val_loss: 0.5249 - val_acc: 0.7610\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5275 - acc: 0.7481 - val_loss: 0.5238 - val_acc: 0.7610\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5148 - acc: 0.7650 - val_loss: 0.5217 - val_acc: 0.7661\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5208 - acc: 0.7534 - val_loss: 0.5187 - val_acc: 0.7746\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5124 - acc: 0.7619 - val_loss: 0.5190 - val_acc: 0.7678\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5150 - acc: 0.7553 - val_loss: 0.5177 - val_acc: 0.7695\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5207 - acc: 0.7525 - val_loss: 0.5192 - val_acc: 0.7593\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5169 - acc: 0.7631 - val_loss: 0.5162 - val_acc: 0.7712\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5126 - acc: 0.7631 - val_loss: 0.5167 - val_acc: 0.7593\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5063 - acc: 0.7634 - val_loss: 0.5142 - val_acc: 0.7729\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5151 - acc: 0.7584 - val_loss: 0.5136 - val_acc: 0.7729\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5015 - acc: 0.7734 - val_loss: 0.5127 - val_acc: 0.7695\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5101 - acc: 0.7753 - val_loss: 0.5096 - val_acc: 0.7746\n",
      "Epoch 61/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5002 - acc: 0.7675 - val_loss: 0.5091 - val_acc: 0.7712\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5029 - acc: 0.7709 - val_loss: 0.5083 - val_acc: 0.7712\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5037 - acc: 0.7725 - val_loss: 0.5066 - val_acc: 0.7746\n",
      "Epoch 64/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.5014 - acc: 0.7731 - val_loss: 0.5066 - val_acc: 0.7746\n",
      "Epoch 65/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5027 - acc: 0.7769 - val_loss: 0.5037 - val_acc: 0.7746\n",
      "Epoch 66/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4940 - acc: 0.7828 - val_loss: 0.5013 - val_acc: 0.7797\n",
      "Epoch 67/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4990 - acc: 0.7853 - val_loss: 0.5032 - val_acc: 0.7763\n",
      "Epoch 68/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4920 - acc: 0.7784 - val_loss: 0.5017 - val_acc: 0.7763\n",
      "Epoch 69/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.5057 - acc: 0.7678 - val_loss: 0.4991 - val_acc: 0.7780\n",
      "Epoch 70/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4872 - acc: 0.7891 - val_loss: 0.4988 - val_acc: 0.7746\n",
      "Epoch 71/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4976 - acc: 0.7781 - val_loss: 0.4980 - val_acc: 0.7746\n",
      "Epoch 72/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4874 - acc: 0.7853 - val_loss: 0.4960 - val_acc: 0.7763\n",
      "Epoch 73/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4951 - acc: 0.7788 - val_loss: 0.4954 - val_acc: 0.7763\n",
      "Epoch 74/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4944 - acc: 0.7688 - val_loss: 0.4942 - val_acc: 0.7763\n",
      "Epoch 75/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4910 - acc: 0.7803 - val_loss: 0.4944 - val_acc: 0.7763\n",
      "Epoch 76/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4877 - acc: 0.7859 - val_loss: 0.4920 - val_acc: 0.7797\n",
      "Epoch 77/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4841 - acc: 0.7891 - val_loss: 0.4908 - val_acc: 0.7831\n",
      "Epoch 78/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4917 - acc: 0.7759 - val_loss: 0.4889 - val_acc: 0.7847\n",
      "Epoch 79/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4896 - acc: 0.7797 - val_loss: 0.4896 - val_acc: 0.7831\n",
      "Epoch 80/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4791 - acc: 0.7956 - val_loss: 0.4904 - val_acc: 0.7797\n",
      "Epoch 81/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4767 - acc: 0.7900 - val_loss: 0.4890 - val_acc: 0.7797\n",
      "Epoch 82/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4755 - acc: 0.7959 - val_loss: 0.4906 - val_acc: 0.7814\n",
      "Epoch 83/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4870 - acc: 0.7775 - val_loss: 0.4869 - val_acc: 0.7814\n",
      "Epoch 84/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4702 - acc: 0.7984 - val_loss: 0.4841 - val_acc: 0.7864\n",
      "Epoch 85/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4733 - acc: 0.7925 - val_loss: 0.4853 - val_acc: 0.7831\n",
      "Epoch 86/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4812 - acc: 0.7781 - val_loss: 0.4847 - val_acc: 0.7814\n",
      "Epoch 87/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4758 - acc: 0.7941 - val_loss: 0.4863 - val_acc: 0.7847\n",
      "Epoch 88/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4782 - acc: 0.7869 - val_loss: 0.4840 - val_acc: 0.7847\n",
      "Epoch 89/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4815 - acc: 0.7762 - val_loss: 0.4821 - val_acc: 0.7881\n",
      "Epoch 90/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4746 - acc: 0.7884 - val_loss: 0.4819 - val_acc: 0.7898\n",
      "Epoch 91/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4660 - acc: 0.8034 - val_loss: 0.4805 - val_acc: 0.7915\n",
      "Epoch 92/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4725 - acc: 0.7928 - val_loss: 0.4797 - val_acc: 0.7915\n",
      "Epoch 93/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4628 - acc: 0.8038 - val_loss: 0.4816 - val_acc: 0.7847\n",
      "Epoch 94/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4701 - acc: 0.7875 - val_loss: 0.4779 - val_acc: 0.7932\n",
      "Epoch 95/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4741 - acc: 0.7891 - val_loss: 0.4765 - val_acc: 0.7915\n",
      "Epoch 96/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4669 - acc: 0.7919 - val_loss: 0.4754 - val_acc: 0.7932\n",
      "Epoch 97/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4638 - acc: 0.8025 - val_loss: 0.4751 - val_acc: 0.7915\n",
      "Epoch 98/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4655 - acc: 0.7937 - val_loss: 0.4736 - val_acc: 0.7932\n",
      "Epoch 99/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4658 - acc: 0.7919 - val_loss: 0.4730 - val_acc: 0.7915\n",
      "Epoch 100/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4621 - acc: 0.8016 - val_loss: 0.4740 - val_acc: 0.7983\n",
      "Epoch 101/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4674 - acc: 0.7950 - val_loss: 0.4729 - val_acc: 0.7983\n",
      "Epoch 102/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4690 - acc: 0.7900 - val_loss: 0.4726 - val_acc: 0.7966\n",
      "Epoch 103/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4605 - acc: 0.8041 - val_loss: 0.4696 - val_acc: 0.7966\n",
      "Epoch 104/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4631 - acc: 0.8075 - val_loss: 0.4717 - val_acc: 0.7983\n",
      "Epoch 105/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4572 - acc: 0.8053 - val_loss: 0.4711 - val_acc: 0.7966\n",
      "Epoch 106/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4593 - acc: 0.8116 - val_loss: 0.4702 - val_acc: 0.7983\n",
      "Epoch 107/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4568 - acc: 0.8072 - val_loss: 0.4693 - val_acc: 0.8000\n",
      "Epoch 108/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4600 - acc: 0.7978 - val_loss: 0.4685 - val_acc: 0.8017\n",
      "Epoch 109/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4465 - acc: 0.8178 - val_loss: 0.4669 - val_acc: 0.8000\n",
      "Epoch 110/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4565 - acc: 0.8113 - val_loss: 0.4681 - val_acc: 0.7983\n",
      "Epoch 111/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4413 - acc: 0.8166 - val_loss: 0.4661 - val_acc: 0.8034\n",
      "Epoch 112/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4575 - acc: 0.7950 - val_loss: 0.4655 - val_acc: 0.8017\n",
      "Epoch 113/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4572 - acc: 0.7969 - val_loss: 0.4645 - val_acc: 0.8017\n",
      "Epoch 114/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4422 - acc: 0.8181 - val_loss: 0.4629 - val_acc: 0.8034\n",
      "Epoch 115/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4542 - acc: 0.7956 - val_loss: 0.4623 - val_acc: 0.8034\n",
      "Epoch 116/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4596 - acc: 0.8059 - val_loss: 0.4628 - val_acc: 0.8034\n",
      "Epoch 117/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4589 - acc: 0.8038 - val_loss: 0.4624 - val_acc: 0.8000\n",
      "Epoch 118/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4486 - acc: 0.8087 - val_loss: 0.4612 - val_acc: 0.8034\n",
      "Epoch 119/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4533 - acc: 0.8031 - val_loss: 0.4632 - val_acc: 0.8017\n",
      "Epoch 120/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4362 - acc: 0.8181 - val_loss: 0.4605 - val_acc: 0.8034\n",
      "Epoch 121/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4464 - acc: 0.8103 - val_loss: 0.4599 - val_acc: 0.8017\n",
      "Epoch 122/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4451 - acc: 0.8113 - val_loss: 0.4610 - val_acc: 0.8034\n",
      "Epoch 123/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4494 - acc: 0.8075 - val_loss: 0.4592 - val_acc: 0.8017\n",
      "Epoch 124/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4394 - acc: 0.8159 - val_loss: 0.4594 - val_acc: 0.8017\n",
      "Epoch 125/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4384 - acc: 0.8097 - val_loss: 0.4577 - val_acc: 0.8034\n",
      "Epoch 126/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4416 - acc: 0.8087 - val_loss: 0.4569 - val_acc: 0.8085\n",
      "Epoch 127/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4413 - acc: 0.8194 - val_loss: 0.4565 - val_acc: 0.8085\n",
      "Epoch 128/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4485 - acc: 0.8053 - val_loss: 0.4567 - val_acc: 0.8034\n",
      "Epoch 129/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4396 - acc: 0.8206 - val_loss: 0.4569 - val_acc: 0.8034\n",
      "Epoch 130/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4296 - acc: 0.8247 - val_loss: 0.4560 - val_acc: 0.8034\n",
      "Epoch 131/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4328 - acc: 0.8219 - val_loss: 0.4550 - val_acc: 0.8068\n",
      "Epoch 132/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4426 - acc: 0.8169 - val_loss: 0.4549 - val_acc: 0.8051\n",
      "Epoch 133/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4422 - acc: 0.8059 - val_loss: 0.4538 - val_acc: 0.8068\n",
      "Epoch 134/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4386 - acc: 0.8116 - val_loss: 0.4556 - val_acc: 0.8034\n",
      "Epoch 135/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4414 - acc: 0.8163 - val_loss: 0.4518 - val_acc: 0.8085\n",
      "Epoch 136/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4356 - acc: 0.8244 - val_loss: 0.4518 - val_acc: 0.8085\n",
      "Epoch 137/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4408 - acc: 0.8144 - val_loss: 0.4534 - val_acc: 0.8068\n",
      "Epoch 138/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4354 - acc: 0.8181 - val_loss: 0.4504 - val_acc: 0.8085\n",
      "Epoch 139/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4372 - acc: 0.8159 - val_loss: 0.4515 - val_acc: 0.8085\n",
      "Epoch 140/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4284 - acc: 0.8300 - val_loss: 0.4487 - val_acc: 0.8102\n",
      "Epoch 141/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4365 - acc: 0.8219 - val_loss: 0.4488 - val_acc: 0.8085\n",
      "Epoch 142/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4429 - acc: 0.8147 - val_loss: 0.4503 - val_acc: 0.8068\n",
      "Epoch 143/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4322 - acc: 0.8262 - val_loss: 0.4489 - val_acc: 0.8068\n",
      "Epoch 144/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4360 - acc: 0.8137 - val_loss: 0.4479 - val_acc: 0.8085\n",
      "Epoch 145/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4340 - acc: 0.8137 - val_loss: 0.4479 - val_acc: 0.8085\n",
      "Epoch 146/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4330 - acc: 0.8187 - val_loss: 0.4485 - val_acc: 0.8102\n",
      "Epoch 147/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4256 - acc: 0.8266 - val_loss: 0.4474 - val_acc: 0.8102\n",
      "Epoch 148/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4340 - acc: 0.8203 - val_loss: 0.4470 - val_acc: 0.8102\n",
      "Epoch 149/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4407 - acc: 0.7988 - val_loss: 0.4467 - val_acc: 0.8102\n",
      "Epoch 150/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4342 - acc: 0.8147 - val_loss: 0.4466 - val_acc: 0.8102\n",
      "Epoch 151/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4354 - acc: 0.8109 - val_loss: 0.4451 - val_acc: 0.8102\n",
      "Epoch 152/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4351 - acc: 0.8125 - val_loss: 0.4441 - val_acc: 0.8136\n",
      "Epoch 153/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4330 - acc: 0.8150 - val_loss: 0.4446 - val_acc: 0.8119\n",
      "Epoch 154/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4295 - acc: 0.8253 - val_loss: 0.4450 - val_acc: 0.8102\n",
      "Epoch 155/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4162 - acc: 0.8331 - val_loss: 0.4452 - val_acc: 0.8136\n",
      "Epoch 156/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4228 - acc: 0.8300 - val_loss: 0.4434 - val_acc: 0.8119\n",
      "Epoch 157/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4370 - acc: 0.8125 - val_loss: 0.4431 - val_acc: 0.8102\n",
      "Epoch 158/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4242 - acc: 0.8237 - val_loss: 0.4446 - val_acc: 0.8119\n",
      "Epoch 159/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4230 - acc: 0.8228 - val_loss: 0.4429 - val_acc: 0.8136\n",
      "Epoch 160/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4309 - acc: 0.8081 - val_loss: 0.4425 - val_acc: 0.8136\n",
      "Epoch 161/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4312 - acc: 0.8181 - val_loss: 0.4412 - val_acc: 0.8136\n",
      "Epoch 162/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4333 - acc: 0.8178 - val_loss: 0.4416 - val_acc: 0.8153\n",
      "Epoch 163/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4213 - acc: 0.8272 - val_loss: 0.4406 - val_acc: 0.8153\n",
      "Epoch 164/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4262 - acc: 0.8259 - val_loss: 0.4410 - val_acc: 0.8136\n",
      "Epoch 165/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4140 - acc: 0.8309 - val_loss: 0.4396 - val_acc: 0.8102\n",
      "Epoch 166/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4101 - acc: 0.8384 - val_loss: 0.4396 - val_acc: 0.8102\n",
      "Epoch 167/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4270 - acc: 0.8219 - val_loss: 0.4384 - val_acc: 0.8102\n",
      "Epoch 168/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4229 - acc: 0.8237 - val_loss: 0.4369 - val_acc: 0.8136\n",
      "Epoch 169/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4207 - acc: 0.8237 - val_loss: 0.4379 - val_acc: 0.8119\n",
      "Epoch 170/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4206 - acc: 0.8316 - val_loss: 0.4380 - val_acc: 0.8136\n",
      "Epoch 171/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4154 - acc: 0.8269 - val_loss: 0.4381 - val_acc: 0.8186\n",
      "Epoch 172/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4177 - acc: 0.8219 - val_loss: 0.4363 - val_acc: 0.8136\n",
      "Epoch 173/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4231 - acc: 0.8253 - val_loss: 0.4357 - val_acc: 0.8136\n",
      "Epoch 174/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4087 - acc: 0.8375 - val_loss: 0.4353 - val_acc: 0.8136\n",
      "Epoch 175/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4183 - acc: 0.8256 - val_loss: 0.4372 - val_acc: 0.8153\n",
      "Epoch 176/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4297 - acc: 0.8197 - val_loss: 0.4386 - val_acc: 0.8203\n",
      "Epoch 177/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4140 - acc: 0.8266 - val_loss: 0.4361 - val_acc: 0.8186\n",
      "Epoch 178/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4228 - acc: 0.8197 - val_loss: 0.4342 - val_acc: 0.8153\n",
      "Epoch 179/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4068 - acc: 0.8363 - val_loss: 0.4353 - val_acc: 0.8203\n",
      "Epoch 180/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4101 - acc: 0.8272 - val_loss: 0.4335 - val_acc: 0.8153\n",
      "Epoch 181/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4179 - acc: 0.8237 - val_loss: 0.4346 - val_acc: 0.8203\n",
      "Epoch 182/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4097 - acc: 0.8400 - val_loss: 0.4331 - val_acc: 0.8136\n",
      "Epoch 183/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4154 - acc: 0.8353 - val_loss: 0.4330 - val_acc: 0.8169\n",
      "Epoch 184/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3990 - acc: 0.8481 - val_loss: 0.4329 - val_acc: 0.8169\n",
      "Epoch 185/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4190 - acc: 0.8284 - val_loss: 0.4318 - val_acc: 0.8169\n",
      "Epoch 186/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4145 - acc: 0.8291 - val_loss: 0.4326 - val_acc: 0.8169\n",
      "Epoch 187/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4139 - acc: 0.8256 - val_loss: 0.4320 - val_acc: 0.8169\n",
      "Epoch 188/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4118 - acc: 0.8266 - val_loss: 0.4328 - val_acc: 0.8186\n",
      "Epoch 189/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4059 - acc: 0.8325 - val_loss: 0.4300 - val_acc: 0.8186\n",
      "Epoch 190/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4147 - acc: 0.8334 - val_loss: 0.4313 - val_acc: 0.8186\n",
      "Epoch 191/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4119 - acc: 0.8219 - val_loss: 0.4297 - val_acc: 0.8203\n",
      "Epoch 192/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4067 - acc: 0.8378 - val_loss: 0.4291 - val_acc: 0.8203\n",
      "Epoch 193/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4076 - acc: 0.8297 - val_loss: 0.4289 - val_acc: 0.8186\n",
      "Epoch 194/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4059 - acc: 0.8375 - val_loss: 0.4301 - val_acc: 0.8220\n",
      "Epoch 195/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4072 - acc: 0.8347 - val_loss: 0.4299 - val_acc: 0.8203\n",
      "Epoch 196/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4087 - acc: 0.8247 - val_loss: 0.4290 - val_acc: 0.8169\n",
      "Epoch 197/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4103 - acc: 0.8203 - val_loss: 0.4298 - val_acc: 0.8186\n",
      "Epoch 198/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4105 - acc: 0.8313 - val_loss: 0.4282 - val_acc: 0.8169\n",
      "Epoch 199/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4025 - acc: 0.8359 - val_loss: 0.4288 - val_acc: 0.8203\n",
      "Epoch 200/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4028 - acc: 0.8366 - val_loss: 0.4285 - val_acc: 0.8203\n",
      "Epoch 201/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4048 - acc: 0.8331 - val_loss: 0.4277 - val_acc: 0.8169\n",
      "Epoch 202/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4054 - acc: 0.8369 - val_loss: 0.4263 - val_acc: 0.8169\n",
      "Epoch 203/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4042 - acc: 0.8350 - val_loss: 0.4260 - val_acc: 0.8169\n",
      "Epoch 204/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4071 - acc: 0.8325 - val_loss: 0.4270 - val_acc: 0.8186\n",
      "Epoch 205/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4121 - acc: 0.8259 - val_loss: 0.4269 - val_acc: 0.8186\n",
      "Epoch 206/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4068 - acc: 0.8316 - val_loss: 0.4258 - val_acc: 0.8169\n",
      "Epoch 207/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3928 - acc: 0.8481 - val_loss: 0.4245 - val_acc: 0.8169\n",
      "Epoch 208/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4082 - acc: 0.8372 - val_loss: 0.4259 - val_acc: 0.8169\n",
      "Epoch 209/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4134 - acc: 0.8350 - val_loss: 0.4254 - val_acc: 0.8186\n",
      "Epoch 210/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4121 - acc: 0.8266 - val_loss: 0.4235 - val_acc: 0.8186\n",
      "Epoch 211/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4065 - acc: 0.8303 - val_loss: 0.4252 - val_acc: 0.8186\n",
      "Epoch 212/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4001 - acc: 0.8366 - val_loss: 0.4243 - val_acc: 0.8169\n",
      "Epoch 213/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3954 - acc: 0.8403 - val_loss: 0.4235 - val_acc: 0.8186\n",
      "Epoch 214/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4141 - acc: 0.8206 - val_loss: 0.4236 - val_acc: 0.8169\n",
      "Epoch 215/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4009 - acc: 0.8403 - val_loss: 0.4241 - val_acc: 0.8169\n",
      "Epoch 216/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.4048 - acc: 0.8278 - val_loss: 0.4233 - val_acc: 0.8169\n",
      "Epoch 217/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3964 - acc: 0.8488 - val_loss: 0.4218 - val_acc: 0.8203\n",
      "Epoch 218/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3920 - acc: 0.8456 - val_loss: 0.4219 - val_acc: 0.8186\n",
      "Epoch 219/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3966 - acc: 0.8375 - val_loss: 0.4223 - val_acc: 0.8169\n",
      "Epoch 220/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3904 - acc: 0.8594 - val_loss: 0.4216 - val_acc: 0.8186\n",
      "Epoch 221/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4005 - acc: 0.8366 - val_loss: 0.4212 - val_acc: 0.8203\n",
      "Epoch 222/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3880 - acc: 0.8481 - val_loss: 0.4206 - val_acc: 0.8237\n",
      "Epoch 223/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4057 - acc: 0.8294 - val_loss: 0.4200 - val_acc: 0.8220\n",
      "Epoch 224/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3960 - acc: 0.8369 - val_loss: 0.4196 - val_acc: 0.8220\n",
      "Epoch 225/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3970 - acc: 0.8334 - val_loss: 0.4206 - val_acc: 0.8186\n",
      "Epoch 226/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3922 - acc: 0.8419 - val_loss: 0.4198 - val_acc: 0.8203\n",
      "Epoch 227/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3931 - acc: 0.8403 - val_loss: 0.4188 - val_acc: 0.8220\n",
      "Epoch 228/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.4035 - acc: 0.8262 - val_loss: 0.4187 - val_acc: 0.8237\n",
      "Epoch 229/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3934 - acc: 0.8462 - val_loss: 0.4182 - val_acc: 0.8220\n",
      "Epoch 230/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3975 - acc: 0.8300 - val_loss: 0.4188 - val_acc: 0.8220\n",
      "Epoch 231/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3894 - acc: 0.8447 - val_loss: 0.4186 - val_acc: 0.8237\n",
      "Epoch 232/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3849 - acc: 0.8459 - val_loss: 0.4182 - val_acc: 0.8237\n",
      "Epoch 233/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4037 - acc: 0.8291 - val_loss: 0.4193 - val_acc: 0.8186\n",
      "Epoch 234/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3981 - acc: 0.8366 - val_loss: 0.4189 - val_acc: 0.8186\n",
      "Epoch 235/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3854 - acc: 0.8409 - val_loss: 0.4182 - val_acc: 0.8203\n",
      "Epoch 236/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3908 - acc: 0.8400 - val_loss: 0.4168 - val_acc: 0.8237\n",
      "Epoch 237/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3870 - acc: 0.8478 - val_loss: 0.4183 - val_acc: 0.8203\n",
      "Epoch 238/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3929 - acc: 0.8341 - val_loss: 0.4172 - val_acc: 0.8220\n",
      "Epoch 239/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3841 - acc: 0.8488 - val_loss: 0.4157 - val_acc: 0.8254\n",
      "Epoch 240/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3919 - acc: 0.8453 - val_loss: 0.4157 - val_acc: 0.8237\n",
      "Epoch 241/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3972 - acc: 0.8325 - val_loss: 0.4140 - val_acc: 0.8237\n",
      "Epoch 242/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3987 - acc: 0.8547 - val_loss: 0.4148 - val_acc: 0.8254\n",
      "Epoch 243/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3852 - acc: 0.8434 - val_loss: 0.4154 - val_acc: 0.8220\n",
      "Epoch 244/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.4001 - acc: 0.8316 - val_loss: 0.4156 - val_acc: 0.8220\n",
      "Epoch 245/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3958 - acc: 0.8397 - val_loss: 0.4152 - val_acc: 0.8220\n",
      "Epoch 246/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3888 - acc: 0.8444 - val_loss: 0.4141 - val_acc: 0.8254\n",
      "Epoch 247/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3889 - acc: 0.8441 - val_loss: 0.4143 - val_acc: 0.8254\n",
      "Epoch 248/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3863 - acc: 0.8441 - val_loss: 0.4128 - val_acc: 0.8237\n",
      "Epoch 249/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3881 - acc: 0.8422 - val_loss: 0.4131 - val_acc: 0.8237\n",
      "Epoch 250/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3910 - acc: 0.8472 - val_loss: 0.4131 - val_acc: 0.8237\n",
      "Epoch 251/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3878 - acc: 0.8453 - val_loss: 0.4127 - val_acc: 0.8237\n",
      "Epoch 252/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3885 - acc: 0.8422 - val_loss: 0.4120 - val_acc: 0.8237\n",
      "Epoch 253/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3924 - acc: 0.8444 - val_loss: 0.4131 - val_acc: 0.8237\n",
      "Epoch 254/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3836 - acc: 0.8478 - val_loss: 0.4116 - val_acc: 0.8254\n",
      "Epoch 255/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3878 - acc: 0.8416 - val_loss: 0.4124 - val_acc: 0.8237\n",
      "Epoch 256/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3852 - acc: 0.8431 - val_loss: 0.4117 - val_acc: 0.8237\n",
      "Epoch 257/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3938 - acc: 0.8438 - val_loss: 0.4126 - val_acc: 0.8220\n",
      "Epoch 258/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3892 - acc: 0.8472 - val_loss: 0.4127 - val_acc: 0.8220\n",
      "Epoch 259/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3908 - acc: 0.8400 - val_loss: 0.4120 - val_acc: 0.8220\n",
      "Epoch 260/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3838 - acc: 0.8478 - val_loss: 0.4116 - val_acc: 0.8203\n",
      "Epoch 261/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3881 - acc: 0.8394 - val_loss: 0.4113 - val_acc: 0.8220\n",
      "Epoch 262/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3894 - acc: 0.8422 - val_loss: 0.4098 - val_acc: 0.8203\n",
      "Epoch 263/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3959 - acc: 0.8350 - val_loss: 0.4099 - val_acc: 0.8220\n",
      "Epoch 264/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3819 - acc: 0.8500 - val_loss: 0.4103 - val_acc: 0.8237\n",
      "Epoch 265/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3862 - acc: 0.8369 - val_loss: 0.4097 - val_acc: 0.8237\n",
      "Epoch 266/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3827 - acc: 0.8441 - val_loss: 0.4104 - val_acc: 0.8237\n",
      "Epoch 267/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3856 - acc: 0.8497 - val_loss: 0.4103 - val_acc: 0.8254\n",
      "Epoch 268/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3839 - acc: 0.8406 - val_loss: 0.4085 - val_acc: 0.8237\n",
      "Epoch 269/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3828 - acc: 0.8475 - val_loss: 0.4088 - val_acc: 0.8220\n",
      "Epoch 270/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3842 - acc: 0.8497 - val_loss: 0.4079 - val_acc: 0.8237\n",
      "Epoch 271/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3732 - acc: 0.8600 - val_loss: 0.4086 - val_acc: 0.8237\n",
      "Epoch 272/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3893 - acc: 0.8444 - val_loss: 0.4100 - val_acc: 0.8271\n",
      "Epoch 273/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3837 - acc: 0.8413 - val_loss: 0.4066 - val_acc: 0.8254\n",
      "Epoch 274/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3739 - acc: 0.8603 - val_loss: 0.4059 - val_acc: 0.8254\n",
      "Epoch 275/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3717 - acc: 0.8581 - val_loss: 0.4071 - val_acc: 0.8254\n",
      "Epoch 276/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3818 - acc: 0.8556 - val_loss: 0.4079 - val_acc: 0.8254\n",
      "Epoch 277/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3851 - acc: 0.8512 - val_loss: 0.4085 - val_acc: 0.8254\n",
      "Epoch 278/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3747 - acc: 0.8559 - val_loss: 0.4078 - val_acc: 0.8254\n",
      "Epoch 279/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3803 - acc: 0.8509 - val_loss: 0.4055 - val_acc: 0.8220\n",
      "Epoch 280/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3811 - acc: 0.8494 - val_loss: 0.4065 - val_acc: 0.8254\n",
      "Epoch 281/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3867 - acc: 0.8500 - val_loss: 0.4055 - val_acc: 0.8254\n",
      "Epoch 282/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3759 - acc: 0.8575 - val_loss: 0.4056 - val_acc: 0.8254\n",
      "Epoch 283/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3796 - acc: 0.8503 - val_loss: 0.4061 - val_acc: 0.8254\n",
      "Epoch 284/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3773 - acc: 0.8512 - val_loss: 0.4055 - val_acc: 0.8254\n",
      "Epoch 285/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3792 - acc: 0.8444 - val_loss: 0.4043 - val_acc: 0.8237\n",
      "Epoch 286/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3800 - acc: 0.8528 - val_loss: 0.4038 - val_acc: 0.8237\n",
      "Epoch 287/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3835 - acc: 0.8503 - val_loss: 0.4052 - val_acc: 0.8254\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3658 - acc: 0.8547 - val_loss: 0.4040 - val_acc: 0.8237\n",
      "Epoch 289/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3877 - acc: 0.8416 - val_loss: 0.4022 - val_acc: 0.8254\n",
      "Epoch 290/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3686 - acc: 0.8556 - val_loss: 0.4019 - val_acc: 0.8254\n",
      "Epoch 291/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3780 - acc: 0.8522 - val_loss: 0.4028 - val_acc: 0.8237\n",
      "Epoch 292/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3791 - acc: 0.8469 - val_loss: 0.4044 - val_acc: 0.8254\n",
      "Epoch 293/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3743 - acc: 0.8506 - val_loss: 0.4028 - val_acc: 0.8237\n",
      "Epoch 294/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3699 - acc: 0.8559 - val_loss: 0.4046 - val_acc: 0.8271\n",
      "Epoch 295/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3751 - acc: 0.8538 - val_loss: 0.4021 - val_acc: 0.8237\n",
      "Epoch 296/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3760 - acc: 0.8538 - val_loss: 0.4029 - val_acc: 0.8254\n",
      "Epoch 297/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3744 - acc: 0.8466 - val_loss: 0.4018 - val_acc: 0.8237\n",
      "Epoch 298/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3704 - acc: 0.8547 - val_loss: 0.4024 - val_acc: 0.8254\n",
      "Epoch 299/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3715 - acc: 0.8562 - val_loss: 0.4028 - val_acc: 0.8254\n",
      "Epoch 300/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3696 - acc: 0.8616 - val_loss: 0.4021 - val_acc: 0.8254\n",
      "Epoch 301/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3676 - acc: 0.8600 - val_loss: 0.4016 - val_acc: 0.8254\n",
      "Epoch 302/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3709 - acc: 0.8525 - val_loss: 0.4000 - val_acc: 0.8237\n",
      "Epoch 303/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3745 - acc: 0.8509 - val_loss: 0.4012 - val_acc: 0.8237\n",
      "Epoch 304/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3786 - acc: 0.8441 - val_loss: 0.4010 - val_acc: 0.8254\n",
      "Epoch 305/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3721 - acc: 0.8528 - val_loss: 0.4003 - val_acc: 0.8254\n",
      "Epoch 306/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3667 - acc: 0.8556 - val_loss: 0.4006 - val_acc: 0.8254\n",
      "Epoch 307/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3864 - acc: 0.8428 - val_loss: 0.4017 - val_acc: 0.8271\n",
      "Epoch 308/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3796 - acc: 0.8481 - val_loss: 0.4019 - val_acc: 0.8271\n",
      "Epoch 309/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3652 - acc: 0.8438 - val_loss: 0.4014 - val_acc: 0.8271\n",
      "Epoch 310/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3570 - acc: 0.8663 - val_loss: 0.4006 - val_acc: 0.8271\n",
      "Epoch 311/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3724 - acc: 0.8494 - val_loss: 0.4008 - val_acc: 0.8271\n",
      "Epoch 312/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3653 - acc: 0.8638 - val_loss: 0.3983 - val_acc: 0.8254\n",
      "Epoch 313/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3663 - acc: 0.8519 - val_loss: 0.3984 - val_acc: 0.8271\n",
      "Epoch 314/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3679 - acc: 0.8562 - val_loss: 0.3978 - val_acc: 0.8254\n",
      "Epoch 315/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3816 - acc: 0.8416 - val_loss: 0.3979 - val_acc: 0.8254\n",
      "Epoch 316/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3675 - acc: 0.8600 - val_loss: 0.3985 - val_acc: 0.8254\n",
      "Epoch 317/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3708 - acc: 0.8634 - val_loss: 0.3981 - val_acc: 0.8254\n",
      "Epoch 318/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3765 - acc: 0.8534 - val_loss: 0.3981 - val_acc: 0.8237\n",
      "Epoch 319/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3632 - acc: 0.8569 - val_loss: 0.3988 - val_acc: 0.8271\n",
      "Epoch 320/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3626 - acc: 0.8584 - val_loss: 0.3980 - val_acc: 0.8254\n",
      "Epoch 321/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3713 - acc: 0.8519 - val_loss: 0.3983 - val_acc: 0.8271\n",
      "Epoch 322/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3640 - acc: 0.8591 - val_loss: 0.3973 - val_acc: 0.8254\n",
      "Epoch 323/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3692 - acc: 0.8497 - val_loss: 0.3968 - val_acc: 0.8254\n",
      "Epoch 324/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3626 - acc: 0.8584 - val_loss: 0.3963 - val_acc: 0.8288\n",
      "Epoch 325/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3618 - acc: 0.8578 - val_loss: 0.3974 - val_acc: 0.8271\n",
      "Epoch 326/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3650 - acc: 0.8587 - val_loss: 0.3960 - val_acc: 0.8288\n",
      "Epoch 327/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3714 - acc: 0.8519 - val_loss: 0.3945 - val_acc: 0.8322\n",
      "Epoch 328/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3674 - acc: 0.8538 - val_loss: 0.3954 - val_acc: 0.8288\n",
      "Epoch 329/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3695 - acc: 0.8569 - val_loss: 0.3962 - val_acc: 0.8254\n",
      "Epoch 330/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3569 - acc: 0.8638 - val_loss: 0.3977 - val_acc: 0.8271\n",
      "Epoch 331/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3564 - acc: 0.8644 - val_loss: 0.3960 - val_acc: 0.8271\n",
      "Epoch 332/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3564 - acc: 0.8697 - val_loss: 0.3961 - val_acc: 0.8271\n",
      "Epoch 333/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3681 - acc: 0.8544 - val_loss: 0.3935 - val_acc: 0.8288\n",
      "Epoch 334/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3576 - acc: 0.8603 - val_loss: 0.3936 - val_acc: 0.8288\n",
      "Epoch 335/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3674 - acc: 0.8547 - val_loss: 0.3942 - val_acc: 0.8305\n",
      "Epoch 336/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3686 - acc: 0.8547 - val_loss: 0.3939 - val_acc: 0.8288\n",
      "Epoch 337/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3598 - acc: 0.8581 - val_loss: 0.3946 - val_acc: 0.8288\n",
      "Epoch 338/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3637 - acc: 0.8562 - val_loss: 0.3942 - val_acc: 0.8288\n",
      "Epoch 339/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3691 - acc: 0.8491 - val_loss: 0.3941 - val_acc: 0.8288\n",
      "Epoch 340/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3685 - acc: 0.8609 - val_loss: 0.3942 - val_acc: 0.8288\n",
      "Epoch 341/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3646 - acc: 0.8569 - val_loss: 0.3938 - val_acc: 0.8288\n",
      "Epoch 342/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3544 - acc: 0.8631 - val_loss: 0.3931 - val_acc: 0.8322\n",
      "Epoch 343/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3666 - acc: 0.8559 - val_loss: 0.3940 - val_acc: 0.8288\n",
      "Epoch 344/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3635 - acc: 0.8572 - val_loss: 0.3950 - val_acc: 0.8254\n",
      "Epoch 345/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3536 - acc: 0.8712 - val_loss: 0.3930 - val_acc: 0.8322\n",
      "Epoch 346/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3613 - acc: 0.8572 - val_loss: 0.3915 - val_acc: 0.8322\n",
      "Epoch 347/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3445 - acc: 0.8719 - val_loss: 0.3926 - val_acc: 0.8305\n",
      "Epoch 348/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3658 - acc: 0.8522 - val_loss: 0.3922 - val_acc: 0.8305\n",
      "Epoch 349/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3552 - acc: 0.8641 - val_loss: 0.3918 - val_acc: 0.8339\n",
      "Epoch 350/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3506 - acc: 0.8650 - val_loss: 0.3927 - val_acc: 0.8305\n",
      "Epoch 351/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3673 - acc: 0.8538 - val_loss: 0.3931 - val_acc: 0.8288\n",
      "Epoch 352/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3581 - acc: 0.8609 - val_loss: 0.3935 - val_acc: 0.8271\n",
      "Epoch 353/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3569 - acc: 0.8613 - val_loss: 0.3926 - val_acc: 0.8305\n",
      "Epoch 354/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3556 - acc: 0.8625 - val_loss: 0.3916 - val_acc: 0.8322\n",
      "Epoch 355/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3638 - acc: 0.8559 - val_loss: 0.3911 - val_acc: 0.8339\n",
      "Epoch 356/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3626 - acc: 0.8559 - val_loss: 0.3905 - val_acc: 0.8339\n",
      "Epoch 357/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3616 - acc: 0.8647 - val_loss: 0.3916 - val_acc: 0.8305\n",
      "Epoch 358/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3566 - acc: 0.8584 - val_loss: 0.3914 - val_acc: 0.8305\n",
      "Epoch 359/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3695 - acc: 0.8550 - val_loss: 0.3907 - val_acc: 0.8322\n",
      "Epoch 360/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3669 - acc: 0.8500 - val_loss: 0.3913 - val_acc: 0.8305\n",
      "Epoch 361/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3643 - acc: 0.8644 - val_loss: 0.3910 - val_acc: 0.8305\n",
      "Epoch 362/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3575 - acc: 0.8628 - val_loss: 0.3899 - val_acc: 0.8322\n",
      "Epoch 363/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3549 - acc: 0.8672 - val_loss: 0.3883 - val_acc: 0.8339\n",
      "Epoch 364/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3599 - acc: 0.8519 - val_loss: 0.3898 - val_acc: 0.8305\n",
      "Epoch 365/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3557 - acc: 0.8725 - val_loss: 0.3896 - val_acc: 0.8322\n",
      "Epoch 366/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3447 - acc: 0.8688 - val_loss: 0.3898 - val_acc: 0.8305\n",
      "Epoch 367/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3544 - acc: 0.8631 - val_loss: 0.3897 - val_acc: 0.8322\n",
      "Epoch 368/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3492 - acc: 0.8659 - val_loss: 0.3887 - val_acc: 0.8322\n",
      "Epoch 369/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3578 - acc: 0.8556 - val_loss: 0.3871 - val_acc: 0.8373\n",
      "Epoch 370/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3533 - acc: 0.8712 - val_loss: 0.3872 - val_acc: 0.8373\n",
      "Epoch 371/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3597 - acc: 0.8600 - val_loss: 0.3880 - val_acc: 0.8322\n",
      "Epoch 372/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3509 - acc: 0.8631 - val_loss: 0.3888 - val_acc: 0.8305\n",
      "Epoch 373/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3540 - acc: 0.8647 - val_loss: 0.3884 - val_acc: 0.8305\n",
      "Epoch 374/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3592 - acc: 0.8600 - val_loss: 0.3884 - val_acc: 0.8305\n",
      "Epoch 375/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3631 - acc: 0.8541 - val_loss: 0.3878 - val_acc: 0.8322\n",
      "Epoch 376/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3444 - acc: 0.8747 - val_loss: 0.3877 - val_acc: 0.8322\n",
      "Epoch 377/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3420 - acc: 0.8778 - val_loss: 0.3885 - val_acc: 0.8288\n",
      "Epoch 378/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3473 - acc: 0.8741 - val_loss: 0.3884 - val_acc: 0.8288\n",
      "Epoch 379/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3522 - acc: 0.8672 - val_loss: 0.3878 - val_acc: 0.8288\n",
      "Epoch 380/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3565 - acc: 0.8544 - val_loss: 0.3876 - val_acc: 0.8288\n",
      "Epoch 381/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3476 - acc: 0.8628 - val_loss: 0.3884 - val_acc: 0.8288\n",
      "Epoch 382/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3483 - acc: 0.8800 - val_loss: 0.3870 - val_acc: 0.8305\n",
      "Epoch 383/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3484 - acc: 0.8631 - val_loss: 0.3868 - val_acc: 0.8305\n",
      "Epoch 384/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3592 - acc: 0.8550 - val_loss: 0.3866 - val_acc: 0.8305\n",
      "Epoch 385/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3511 - acc: 0.8616 - val_loss: 0.3868 - val_acc: 0.8305\n",
      "Epoch 386/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3516 - acc: 0.8619 - val_loss: 0.3870 - val_acc: 0.8288\n",
      "Epoch 387/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3528 - acc: 0.8675 - val_loss: 0.3869 - val_acc: 0.8305\n",
      "Epoch 388/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3530 - acc: 0.8622 - val_loss: 0.3859 - val_acc: 0.8339\n",
      "Epoch 389/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3574 - acc: 0.8613 - val_loss: 0.3858 - val_acc: 0.8339\n",
      "Epoch 390/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3579 - acc: 0.8584 - val_loss: 0.3854 - val_acc: 0.8339\n",
      "Epoch 391/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3501 - acc: 0.8619 - val_loss: 0.3849 - val_acc: 0.8339\n",
      "Epoch 392/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3429 - acc: 0.8719 - val_loss: 0.3845 - val_acc: 0.8339\n",
      "Epoch 393/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3537 - acc: 0.8628 - val_loss: 0.3845 - val_acc: 0.8339\n",
      "Epoch 394/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3466 - acc: 0.8716 - val_loss: 0.3839 - val_acc: 0.8339\n",
      "Epoch 395/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3478 - acc: 0.8659 - val_loss: 0.3839 - val_acc: 0.8339\n",
      "Epoch 396/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3507 - acc: 0.8700 - val_loss: 0.3844 - val_acc: 0.8339\n",
      "Epoch 397/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3423 - acc: 0.8706 - val_loss: 0.3855 - val_acc: 0.8322\n",
      "Epoch 398/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3526 - acc: 0.8644 - val_loss: 0.3852 - val_acc: 0.8322\n",
      "Epoch 399/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3467 - acc: 0.8650 - val_loss: 0.3845 - val_acc: 0.8339\n",
      "Epoch 400/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3616 - acc: 0.8625 - val_loss: 0.3853 - val_acc: 0.8322\n",
      "Epoch 401/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3595 - acc: 0.8663 - val_loss: 0.3836 - val_acc: 0.8339\n",
      "Epoch 402/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3538 - acc: 0.8631 - val_loss: 0.3831 - val_acc: 0.8339\n",
      "Epoch 403/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3500 - acc: 0.8653 - val_loss: 0.3833 - val_acc: 0.8339\n",
      "Epoch 404/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3462 - acc: 0.8731 - val_loss: 0.3840 - val_acc: 0.8339\n",
      "Epoch 405/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3504 - acc: 0.8669 - val_loss: 0.3841 - val_acc: 0.8339\n",
      "Epoch 406/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3494 - acc: 0.8663 - val_loss: 0.3831 - val_acc: 0.8339\n",
      "Epoch 407/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3552 - acc: 0.8594 - val_loss: 0.3822 - val_acc: 0.8339\n",
      "Epoch 408/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3525 - acc: 0.8584 - val_loss: 0.3829 - val_acc: 0.8339\n",
      "Epoch 409/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3404 - acc: 0.8762 - val_loss: 0.3821 - val_acc: 0.8356\n",
      "Epoch 410/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3496 - acc: 0.8672 - val_loss: 0.3836 - val_acc: 0.8322\n",
      "Epoch 411/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3356 - acc: 0.8788 - val_loss: 0.3832 - val_acc: 0.8339\n",
      "Epoch 412/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3565 - acc: 0.8575 - val_loss: 0.3839 - val_acc: 0.8322\n",
      "Epoch 413/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3455 - acc: 0.8656 - val_loss: 0.3816 - val_acc: 0.8356\n",
      "Epoch 414/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3394 - acc: 0.8775 - val_loss: 0.3825 - val_acc: 0.8339\n",
      "Epoch 415/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3528 - acc: 0.8597 - val_loss: 0.3824 - val_acc: 0.8339\n",
      "Epoch 416/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3489 - acc: 0.8650 - val_loss: 0.3817 - val_acc: 0.8339\n",
      "Epoch 417/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3468 - acc: 0.8647 - val_loss: 0.3814 - val_acc: 0.8339\n",
      "Epoch 418/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3488 - acc: 0.8644 - val_loss: 0.3814 - val_acc: 0.8339\n",
      "Epoch 419/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3458 - acc: 0.8656 - val_loss: 0.3814 - val_acc: 0.8339\n",
      "Epoch 420/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3311 - acc: 0.8816 - val_loss: 0.3816 - val_acc: 0.8339\n",
      "Epoch 421/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3538 - acc: 0.8647 - val_loss: 0.3807 - val_acc: 0.8390\n",
      "Epoch 422/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3389 - acc: 0.8738 - val_loss: 0.3805 - val_acc: 0.8390\n",
      "Epoch 423/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3495 - acc: 0.8631 - val_loss: 0.3804 - val_acc: 0.8390\n",
      "Epoch 424/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3401 - acc: 0.8744 - val_loss: 0.3807 - val_acc: 0.8339\n",
      "Epoch 425/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3352 - acc: 0.8747 - val_loss: 0.3815 - val_acc: 0.8322\n",
      "Epoch 426/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3445 - acc: 0.8644 - val_loss: 0.3814 - val_acc: 0.8322\n",
      "Epoch 427/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3523 - acc: 0.8587 - val_loss: 0.3813 - val_acc: 0.8322\n",
      "Epoch 428/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3481 - acc: 0.8616 - val_loss: 0.3803 - val_acc: 0.8339\n",
      "Epoch 429/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3409 - acc: 0.8709 - val_loss: 0.3806 - val_acc: 0.8339\n",
      "Epoch 430/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3465 - acc: 0.8706 - val_loss: 0.3794 - val_acc: 0.8390\n",
      "Epoch 431/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3471 - acc: 0.8644 - val_loss: 0.3797 - val_acc: 0.8322\n",
      "Epoch 432/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3475 - acc: 0.8531 - val_loss: 0.3801 - val_acc: 0.8339\n",
      "Epoch 433/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3374 - acc: 0.8734 - val_loss: 0.3810 - val_acc: 0.8322\n",
      "Epoch 434/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3458 - acc: 0.8647 - val_loss: 0.3800 - val_acc: 0.8339\n",
      "Epoch 435/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3401 - acc: 0.8691 - val_loss: 0.3802 - val_acc: 0.8322\n",
      "Epoch 436/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3446 - acc: 0.8653 - val_loss: 0.3798 - val_acc: 0.8339\n",
      "Epoch 437/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3428 - acc: 0.8681 - val_loss: 0.3796 - val_acc: 0.8339\n",
      "Epoch 438/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3432 - acc: 0.8688 - val_loss: 0.3792 - val_acc: 0.8373\n",
      "Epoch 439/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3377 - acc: 0.8634 - val_loss: 0.3777 - val_acc: 0.8424\n",
      "Epoch 440/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3318 - acc: 0.8747 - val_loss: 0.3781 - val_acc: 0.8424\n",
      "Epoch 441/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3371 - acc: 0.8675 - val_loss: 0.3766 - val_acc: 0.8424\n",
      "Epoch 442/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3437 - acc: 0.8656 - val_loss: 0.3782 - val_acc: 0.8390\n",
      "Epoch 443/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3495 - acc: 0.8631 - val_loss: 0.3777 - val_acc: 0.8407\n",
      "Epoch 444/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3437 - acc: 0.8616 - val_loss: 0.3768 - val_acc: 0.8441\n",
      "Epoch 445/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3382 - acc: 0.8644 - val_loss: 0.3773 - val_acc: 0.8424\n",
      "Epoch 446/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3368 - acc: 0.8712 - val_loss: 0.3777 - val_acc: 0.8390\n",
      "Epoch 447/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3401 - acc: 0.8694 - val_loss: 0.3770 - val_acc: 0.8407\n",
      "Epoch 448/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3383 - acc: 0.8772 - val_loss: 0.3768 - val_acc: 0.8424\n",
      "Epoch 449/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3473 - acc: 0.8653 - val_loss: 0.3776 - val_acc: 0.8373\n",
      "Epoch 450/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3326 - acc: 0.8734 - val_loss: 0.3768 - val_acc: 0.8390\n",
      "Epoch 451/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3477 - acc: 0.8663 - val_loss: 0.3777 - val_acc: 0.8356\n",
      "Epoch 452/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3368 - acc: 0.8672 - val_loss: 0.3772 - val_acc: 0.8373\n",
      "Epoch 453/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3545 - acc: 0.8566 - val_loss: 0.3773 - val_acc: 0.8373\n",
      "Epoch 454/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3442 - acc: 0.8622 - val_loss: 0.3770 - val_acc: 0.8373\n",
      "Epoch 455/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3400 - acc: 0.8672 - val_loss: 0.3762 - val_acc: 0.8407\n",
      "Epoch 456/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3431 - acc: 0.8634 - val_loss: 0.3753 - val_acc: 0.8424\n",
      "Epoch 457/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3348 - acc: 0.8750 - val_loss: 0.3758 - val_acc: 0.8390\n",
      "Epoch 458/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3382 - acc: 0.8703 - val_loss: 0.3761 - val_acc: 0.8373\n",
      "Epoch 459/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3424 - acc: 0.8619 - val_loss: 0.3763 - val_acc: 0.8373\n",
      "Epoch 460/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3328 - acc: 0.8728 - val_loss: 0.3762 - val_acc: 0.8373\n",
      "Epoch 461/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3250 - acc: 0.8847 - val_loss: 0.3751 - val_acc: 0.8424\n",
      "Epoch 462/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3321 - acc: 0.8738 - val_loss: 0.3753 - val_acc: 0.8407\n",
      "Epoch 463/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3374 - acc: 0.8678 - val_loss: 0.3754 - val_acc: 0.8390\n",
      "Epoch 464/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3361 - acc: 0.8731 - val_loss: 0.3754 - val_acc: 0.8390\n",
      "Epoch 465/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3384 - acc: 0.8769 - val_loss: 0.3750 - val_acc: 0.8390\n",
      "Epoch 466/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3335 - acc: 0.8766 - val_loss: 0.3747 - val_acc: 0.8424\n",
      "Epoch 467/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3322 - acc: 0.8728 - val_loss: 0.3758 - val_acc: 0.8373\n",
      "Epoch 468/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3332 - acc: 0.8791 - val_loss: 0.3753 - val_acc: 0.8373\n",
      "Epoch 469/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3468 - acc: 0.8581 - val_loss: 0.3757 - val_acc: 0.8373\n",
      "Epoch 470/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3287 - acc: 0.8697 - val_loss: 0.3750 - val_acc: 0.8390\n",
      "Epoch 471/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3307 - acc: 0.8772 - val_loss: 0.3750 - val_acc: 0.8373\n",
      "Epoch 472/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3335 - acc: 0.8684 - val_loss: 0.3749 - val_acc: 0.8373\n",
      "Epoch 473/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3355 - acc: 0.8725 - val_loss: 0.3746 - val_acc: 0.8390\n",
      "Epoch 474/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3224 - acc: 0.8862 - val_loss: 0.3745 - val_acc: 0.8373\n",
      "Epoch 475/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3269 - acc: 0.8759 - val_loss: 0.3745 - val_acc: 0.8373\n",
      "Epoch 476/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3219 - acc: 0.8866 - val_loss: 0.3747 - val_acc: 0.8356\n",
      "Epoch 477/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3267 - acc: 0.8762 - val_loss: 0.3755 - val_acc: 0.8356\n",
      "Epoch 478/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3310 - acc: 0.8738 - val_loss: 0.3744 - val_acc: 0.8356\n",
      "Epoch 479/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3228 - acc: 0.8800 - val_loss: 0.3730 - val_acc: 0.8407\n",
      "Epoch 480/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3288 - acc: 0.8750 - val_loss: 0.3739 - val_acc: 0.8373\n",
      "Epoch 481/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3358 - acc: 0.8697 - val_loss: 0.3731 - val_acc: 0.8407\n",
      "Epoch 482/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3299 - acc: 0.8747 - val_loss: 0.3729 - val_acc: 0.8407\n",
      "Epoch 483/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3308 - acc: 0.8812 - val_loss: 0.3735 - val_acc: 0.8407\n",
      "Epoch 484/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3353 - acc: 0.8700 - val_loss: 0.3739 - val_acc: 0.8356\n",
      "Epoch 485/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3318 - acc: 0.8794 - val_loss: 0.3739 - val_acc: 0.8356\n",
      "Epoch 486/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3390 - acc: 0.8653 - val_loss: 0.3740 - val_acc: 0.8356\n",
      "Epoch 487/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3363 - acc: 0.8688 - val_loss: 0.3733 - val_acc: 0.8390\n",
      "Epoch 488/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3395 - acc: 0.8638 - val_loss: 0.3722 - val_acc: 0.8407\n",
      "Epoch 489/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3382 - acc: 0.8762 - val_loss: 0.3722 - val_acc: 0.8407\n",
      "Epoch 490/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3318 - acc: 0.8728 - val_loss: 0.3725 - val_acc: 0.8407\n",
      "Epoch 491/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3420 - acc: 0.8666 - val_loss: 0.3718 - val_acc: 0.8407\n",
      "Epoch 492/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3345 - acc: 0.8744 - val_loss: 0.3708 - val_acc: 0.8407\n",
      "Epoch 493/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3286 - acc: 0.8700 - val_loss: 0.3716 - val_acc: 0.8407\n",
      "Epoch 494/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3257 - acc: 0.8847 - val_loss: 0.3719 - val_acc: 0.8407\n",
      "Epoch 495/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3368 - acc: 0.8706 - val_loss: 0.3733 - val_acc: 0.8373\n",
      "Epoch 496/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3339 - acc: 0.8781 - val_loss: 0.3726 - val_acc: 0.8373\n",
      "Epoch 497/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3222 - acc: 0.8791 - val_loss: 0.3725 - val_acc: 0.8373\n",
      "Epoch 498/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3329 - acc: 0.8675 - val_loss: 0.3729 - val_acc: 0.8373\n",
      "Epoch 499/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3267 - acc: 0.8753 - val_loss: 0.3732 - val_acc: 0.8339\n",
      "Epoch 500/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3403 - acc: 0.8653 - val_loss: 0.3717 - val_acc: 0.8407\n",
      "Epoch 501/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3262 - acc: 0.8781 - val_loss: 0.3710 - val_acc: 0.8407\n",
      "Epoch 502/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3261 - acc: 0.8837 - val_loss: 0.3716 - val_acc: 0.8390\n",
      "Epoch 503/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3388 - acc: 0.8672 - val_loss: 0.3703 - val_acc: 0.8407\n",
      "Epoch 504/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3319 - acc: 0.8694 - val_loss: 0.3708 - val_acc: 0.8407\n",
      "Epoch 505/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3279 - acc: 0.8722 - val_loss: 0.3710 - val_acc: 0.8407\n",
      "Epoch 506/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3266 - acc: 0.8828 - val_loss: 0.3713 - val_acc: 0.8373\n",
      "Epoch 507/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3339 - acc: 0.8709 - val_loss: 0.3708 - val_acc: 0.8390\n",
      "Epoch 508/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3266 - acc: 0.8856 - val_loss: 0.3720 - val_acc: 0.8373\n",
      "Epoch 509/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3299 - acc: 0.8856 - val_loss: 0.3701 - val_acc: 0.8407\n",
      "Epoch 510/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3150 - acc: 0.8875 - val_loss: 0.3697 - val_acc: 0.8407\n",
      "Epoch 511/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3299 - acc: 0.8750 - val_loss: 0.3705 - val_acc: 0.8390\n",
      "Epoch 512/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3269 - acc: 0.8738 - val_loss: 0.3696 - val_acc: 0.8407\n",
      "Epoch 513/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3272 - acc: 0.8741 - val_loss: 0.3691 - val_acc: 0.8407\n",
      "Epoch 514/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3253 - acc: 0.8850 - val_loss: 0.3692 - val_acc: 0.8407\n",
      "Epoch 515/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3291 - acc: 0.8741 - val_loss: 0.3698 - val_acc: 0.8390\n",
      "Epoch 516/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3292 - acc: 0.8703 - val_loss: 0.3702 - val_acc: 0.8390\n",
      "Epoch 517/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3190 - acc: 0.8794 - val_loss: 0.3707 - val_acc: 0.8373\n",
      "Epoch 518/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3185 - acc: 0.8859 - val_loss: 0.3699 - val_acc: 0.8373\n",
      "Epoch 519/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3308 - acc: 0.8728 - val_loss: 0.3694 - val_acc: 0.8390\n",
      "Epoch 520/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3288 - acc: 0.8722 - val_loss: 0.3705 - val_acc: 0.8373\n",
      "Epoch 521/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3301 - acc: 0.8681 - val_loss: 0.3700 - val_acc: 0.8373\n",
      "Epoch 522/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3227 - acc: 0.8762 - val_loss: 0.3692 - val_acc: 0.8390\n",
      "Epoch 523/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3261 - acc: 0.8753 - val_loss: 0.3685 - val_acc: 0.8407\n",
      "Epoch 524/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3242 - acc: 0.8844 - val_loss: 0.3701 - val_acc: 0.8373\n",
      "Epoch 525/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3289 - acc: 0.8744 - val_loss: 0.3691 - val_acc: 0.8390\n",
      "Epoch 526/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3199 - acc: 0.8816 - val_loss: 0.3692 - val_acc: 0.8390\n",
      "Epoch 527/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3194 - acc: 0.8828 - val_loss: 0.3680 - val_acc: 0.8407\n",
      "Epoch 528/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3273 - acc: 0.8744 - val_loss: 0.3696 - val_acc: 0.8390\n",
      "Epoch 529/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3326 - acc: 0.8756 - val_loss: 0.3693 - val_acc: 0.8390\n",
      "Epoch 530/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3266 - acc: 0.8775 - val_loss: 0.3696 - val_acc: 0.8407\n",
      "Epoch 531/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3289 - acc: 0.8728 - val_loss: 0.3679 - val_acc: 0.8390\n",
      "Epoch 532/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3296 - acc: 0.8759 - val_loss: 0.3679 - val_acc: 0.8390\n",
      "Epoch 533/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3161 - acc: 0.8781 - val_loss: 0.3683 - val_acc: 0.8390\n",
      "Epoch 534/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3324 - acc: 0.8712 - val_loss: 0.3675 - val_acc: 0.8390\n",
      "Epoch 535/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3305 - acc: 0.8703 - val_loss: 0.3682 - val_acc: 0.8390\n",
      "Epoch 536/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3198 - acc: 0.8819 - val_loss: 0.3669 - val_acc: 0.8424\n",
      "Epoch 537/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3289 - acc: 0.8688 - val_loss: 0.3687 - val_acc: 0.8390\n",
      "Epoch 538/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3258 - acc: 0.8778 - val_loss: 0.3679 - val_acc: 0.8373\n",
      "Epoch 539/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3177 - acc: 0.8794 - val_loss: 0.3664 - val_acc: 0.8441\n",
      "Epoch 540/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3319 - acc: 0.8781 - val_loss: 0.3669 - val_acc: 0.8390\n",
      "Epoch 541/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3197 - acc: 0.8841 - val_loss: 0.3667 - val_acc: 0.8390\n",
      "Epoch 542/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3240 - acc: 0.8769 - val_loss: 0.3673 - val_acc: 0.8373\n",
      "Epoch 543/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3255 - acc: 0.8734 - val_loss: 0.3666 - val_acc: 0.8390\n",
      "Epoch 544/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3258 - acc: 0.8791 - val_loss: 0.3664 - val_acc: 0.8424\n",
      "Epoch 545/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3256 - acc: 0.8725 - val_loss: 0.3666 - val_acc: 0.8390\n",
      "Epoch 546/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3319 - acc: 0.8719 - val_loss: 0.3667 - val_acc: 0.8390\n",
      "Epoch 547/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3241 - acc: 0.8762 - val_loss: 0.3664 - val_acc: 0.8390\n",
      "Epoch 548/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3230 - acc: 0.8794 - val_loss: 0.3669 - val_acc: 0.8390\n",
      "Epoch 549/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3194 - acc: 0.8759 - val_loss: 0.3668 - val_acc: 0.8390\n",
      "Epoch 550/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3184 - acc: 0.8859 - val_loss: 0.3661 - val_acc: 0.8390\n",
      "Epoch 551/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3278 - acc: 0.8756 - val_loss: 0.3656 - val_acc: 0.8424\n",
      "Epoch 552/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3290 - acc: 0.8675 - val_loss: 0.3661 - val_acc: 0.8390\n",
      "Epoch 553/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3207 - acc: 0.8803 - val_loss: 0.3658 - val_acc: 0.8390\n",
      "Epoch 554/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3241 - acc: 0.8788 - val_loss: 0.3668 - val_acc: 0.8390\n",
      "Epoch 555/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3117 - acc: 0.8900 - val_loss: 0.3646 - val_acc: 0.8441\n",
      "Epoch 556/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3178 - acc: 0.8825 - val_loss: 0.3655 - val_acc: 0.8390\n",
      "Epoch 557/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3289 - acc: 0.8719 - val_loss: 0.3655 - val_acc: 0.8390\n",
      "Epoch 558/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3235 - acc: 0.8750 - val_loss: 0.3651 - val_acc: 0.8390\n",
      "Epoch 559/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3173 - acc: 0.8841 - val_loss: 0.3649 - val_acc: 0.8407\n",
      "Epoch 560/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3220 - acc: 0.8738 - val_loss: 0.3651 - val_acc: 0.8424\n",
      "Epoch 561/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3203 - acc: 0.8806 - val_loss: 0.3644 - val_acc: 0.8424\n",
      "Epoch 562/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3195 - acc: 0.8806 - val_loss: 0.3648 - val_acc: 0.8441\n",
      "Epoch 563/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3232 - acc: 0.8734 - val_loss: 0.3650 - val_acc: 0.8424\n",
      "Epoch 564/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3259 - acc: 0.8747 - val_loss: 0.3641 - val_acc: 0.8441\n",
      "Epoch 565/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3258 - acc: 0.8769 - val_loss: 0.3640 - val_acc: 0.8441\n",
      "Epoch 566/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3147 - acc: 0.8825 - val_loss: 0.3637 - val_acc: 0.8441\n",
      "Epoch 567/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3194 - acc: 0.8788 - val_loss: 0.3637 - val_acc: 0.8441\n",
      "Epoch 568/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3250 - acc: 0.8859 - val_loss: 0.3639 - val_acc: 0.8441\n",
      "Epoch 569/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3211 - acc: 0.8728 - val_loss: 0.3629 - val_acc: 0.8475\n",
      "Epoch 570/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3325 - acc: 0.8678 - val_loss: 0.3638 - val_acc: 0.8441\n",
      "Epoch 571/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3240 - acc: 0.8694 - val_loss: 0.3637 - val_acc: 0.8441\n",
      "Epoch 572/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3128 - acc: 0.8809 - val_loss: 0.3633 - val_acc: 0.8441\n",
      "Epoch 573/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3199 - acc: 0.8812 - val_loss: 0.3632 - val_acc: 0.8441\n",
      "Epoch 574/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3210 - acc: 0.8828 - val_loss: 0.3639 - val_acc: 0.8441\n",
      "Epoch 575/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3271 - acc: 0.8734 - val_loss: 0.3639 - val_acc: 0.8441\n",
      "Epoch 576/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3083 - acc: 0.8906 - val_loss: 0.3637 - val_acc: 0.8441\n",
      "Epoch 577/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3203 - acc: 0.8828 - val_loss: 0.3633 - val_acc: 0.8441\n",
      "Epoch 578/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3173 - acc: 0.8788 - val_loss: 0.3628 - val_acc: 0.8441\n",
      "Epoch 579/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3214 - acc: 0.8741 - val_loss: 0.3625 - val_acc: 0.8441\n",
      "Epoch 580/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3308 - acc: 0.8722 - val_loss: 0.3623 - val_acc: 0.8458\n",
      "Epoch 581/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3186 - acc: 0.8784 - val_loss: 0.3626 - val_acc: 0.8441\n",
      "Epoch 582/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3060 - acc: 0.8884 - val_loss: 0.3611 - val_acc: 0.8475\n",
      "Epoch 583/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3299 - acc: 0.8719 - val_loss: 0.3636 - val_acc: 0.8424\n",
      "Epoch 584/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3122 - acc: 0.8875 - val_loss: 0.3624 - val_acc: 0.8441\n",
      "Epoch 585/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3220 - acc: 0.8778 - val_loss: 0.3622 - val_acc: 0.8441\n",
      "Epoch 586/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3150 - acc: 0.8797 - val_loss: 0.3625 - val_acc: 0.8441\n",
      "Epoch 587/2000\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.3164 - acc: 0.8747 - val_loss: 0.3614 - val_acc: 0.8458\n",
      "Epoch 588/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3289 - acc: 0.8788 - val_loss: 0.3609 - val_acc: 0.8475\n",
      "Epoch 589/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3176 - acc: 0.8812 - val_loss: 0.3619 - val_acc: 0.8441\n",
      "Epoch 590/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3190 - acc: 0.8816 - val_loss: 0.3613 - val_acc: 0.8458\n",
      "Epoch 591/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3181 - acc: 0.8853 - val_loss: 0.3608 - val_acc: 0.8475\n",
      "Epoch 592/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3164 - acc: 0.8809 - val_loss: 0.3615 - val_acc: 0.8458\n",
      "Epoch 593/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3148 - acc: 0.8791 - val_loss: 0.3612 - val_acc: 0.8458\n",
      "Epoch 594/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3210 - acc: 0.8834 - val_loss: 0.3622 - val_acc: 0.8424\n",
      "Epoch 595/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3142 - acc: 0.8878 - val_loss: 0.3612 - val_acc: 0.8458\n",
      "Epoch 596/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3103 - acc: 0.8831 - val_loss: 0.3602 - val_acc: 0.8458\n",
      "Epoch 597/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3171 - acc: 0.8788 - val_loss: 0.3611 - val_acc: 0.8458\n",
      "Epoch 598/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3170 - acc: 0.8781 - val_loss: 0.3611 - val_acc: 0.8458\n",
      "Epoch 599/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3200 - acc: 0.8784 - val_loss: 0.3610 - val_acc: 0.8458\n",
      "Epoch 600/2000\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.3249 - acc: 0.8756 - val_loss: 0.3608 - val_acc: 0.8458\n",
      "Epoch 601/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3226 - acc: 0.8800 - val_loss: 0.3617 - val_acc: 0.8441\n",
      "Epoch 602/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3140 - acc: 0.8847 - val_loss: 0.3606 - val_acc: 0.8458\n",
      "Epoch 603/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3046 - acc: 0.8909 - val_loss: 0.3605 - val_acc: 0.8458\n",
      "Epoch 604/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3139 - acc: 0.8881 - val_loss: 0.3604 - val_acc: 0.8475\n",
      "Epoch 605/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3140 - acc: 0.8841 - val_loss: 0.3593 - val_acc: 0.8475\n",
      "Epoch 606/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3200 - acc: 0.8797 - val_loss: 0.3589 - val_acc: 0.8458\n",
      "Epoch 607/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3210 - acc: 0.8822 - val_loss: 0.3600 - val_acc: 0.8475\n",
      "Epoch 608/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3199 - acc: 0.8756 - val_loss: 0.3597 - val_acc: 0.8475\n",
      "Epoch 609/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3133 - acc: 0.8831 - val_loss: 0.3593 - val_acc: 0.8475\n",
      "Epoch 610/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3146 - acc: 0.8781 - val_loss: 0.3588 - val_acc: 0.8475\n",
      "Epoch 611/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3240 - acc: 0.8675 - val_loss: 0.3595 - val_acc: 0.8475\n",
      "Epoch 612/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3096 - acc: 0.8853 - val_loss: 0.3603 - val_acc: 0.8441\n",
      "Epoch 613/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3148 - acc: 0.8819 - val_loss: 0.3595 - val_acc: 0.8475\n",
      "Epoch 614/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3204 - acc: 0.8778 - val_loss: 0.3590 - val_acc: 0.8475\n",
      "Epoch 615/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3108 - acc: 0.8841 - val_loss: 0.3589 - val_acc: 0.8475\n",
      "Epoch 616/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3185 - acc: 0.8831 - val_loss: 0.3590 - val_acc: 0.8475\n",
      "Epoch 617/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3115 - acc: 0.8925 - val_loss: 0.3597 - val_acc: 0.8458\n",
      "Epoch 618/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3153 - acc: 0.8756 - val_loss: 0.3586 - val_acc: 0.8475\n",
      "Epoch 619/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3089 - acc: 0.8859 - val_loss: 0.3584 - val_acc: 0.8475\n",
      "Epoch 620/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3223 - acc: 0.8759 - val_loss: 0.3591 - val_acc: 0.8458\n",
      "Epoch 621/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3125 - acc: 0.8872 - val_loss: 0.3583 - val_acc: 0.8475\n",
      "Epoch 622/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3149 - acc: 0.8797 - val_loss: 0.3585 - val_acc: 0.8475\n",
      "Epoch 623/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3212 - acc: 0.8766 - val_loss: 0.3589 - val_acc: 0.8458\n",
      "Epoch 624/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3041 - acc: 0.8788 - val_loss: 0.3582 - val_acc: 0.8475\n",
      "Epoch 625/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3123 - acc: 0.8831 - val_loss: 0.3589 - val_acc: 0.8458\n",
      "Epoch 626/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3110 - acc: 0.8828 - val_loss: 0.3574 - val_acc: 0.8458\n",
      "Epoch 627/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3188 - acc: 0.8797 - val_loss: 0.3571 - val_acc: 0.8458\n",
      "Epoch 628/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3127 - acc: 0.8825 - val_loss: 0.3576 - val_acc: 0.8475\n",
      "Epoch 629/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3177 - acc: 0.8803 - val_loss: 0.3580 - val_acc: 0.8475\n",
      "Epoch 630/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3153 - acc: 0.8806 - val_loss: 0.3577 - val_acc: 0.8475\n",
      "Epoch 631/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3091 - acc: 0.8841 - val_loss: 0.3574 - val_acc: 0.8475\n",
      "Epoch 632/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3116 - acc: 0.8816 - val_loss: 0.3579 - val_acc: 0.8475\n",
      "Epoch 633/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3138 - acc: 0.8822 - val_loss: 0.3575 - val_acc: 0.8475\n",
      "Epoch 634/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3098 - acc: 0.8913 - val_loss: 0.3576 - val_acc: 0.8475\n",
      "Epoch 635/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3124 - acc: 0.8784 - val_loss: 0.3575 - val_acc: 0.8475\n",
      "Epoch 636/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3004 - acc: 0.8919 - val_loss: 0.3567 - val_acc: 0.8475\n",
      "Epoch 637/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3110 - acc: 0.8831 - val_loss: 0.3567 - val_acc: 0.8475\n",
      "Epoch 638/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3051 - acc: 0.8887 - val_loss: 0.3572 - val_acc: 0.8475\n",
      "Epoch 639/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3107 - acc: 0.8844 - val_loss: 0.3574 - val_acc: 0.8475\n",
      "Epoch 640/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3071 - acc: 0.8903 - val_loss: 0.3563 - val_acc: 0.8475\n",
      "Epoch 641/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3145 - acc: 0.8797 - val_loss: 0.3574 - val_acc: 0.8475\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3168 - acc: 0.8812 - val_loss: 0.3564 - val_acc: 0.8475\n",
      "Epoch 643/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3084 - acc: 0.8938 - val_loss: 0.3560 - val_acc: 0.8475\n",
      "Epoch 644/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3092 - acc: 0.8850 - val_loss: 0.3561 - val_acc: 0.8475\n",
      "Epoch 645/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3021 - acc: 0.8887 - val_loss: 0.3564 - val_acc: 0.8475\n",
      "Epoch 646/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3087 - acc: 0.8866 - val_loss: 0.3566 - val_acc: 0.8475\n",
      "Epoch 647/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3182 - acc: 0.8788 - val_loss: 0.3561 - val_acc: 0.8475\n",
      "Epoch 648/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3109 - acc: 0.8850 - val_loss: 0.3571 - val_acc: 0.8475\n",
      "Epoch 649/2000\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.3101 - acc: 0.8894 - val_loss: 0.3579 - val_acc: 0.8458\n",
      "Epoch 650/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3039 - acc: 0.8862 - val_loss: 0.3566 - val_acc: 0.8475\n",
      "Epoch 651/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3194 - acc: 0.8712 - val_loss: 0.3564 - val_acc: 0.8475\n",
      "Epoch 652/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3116 - acc: 0.8797 - val_loss: 0.3568 - val_acc: 0.8458\n",
      "Epoch 653/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3009 - acc: 0.8853 - val_loss: 0.3570 - val_acc: 0.8458\n",
      "Epoch 654/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2986 - acc: 0.8878 - val_loss: 0.3574 - val_acc: 0.8458\n",
      "Epoch 655/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3024 - acc: 0.8916 - val_loss: 0.3564 - val_acc: 0.8458\n",
      "Epoch 656/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3180 - acc: 0.8794 - val_loss: 0.3563 - val_acc: 0.8458\n",
      "Epoch 657/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.2993 - acc: 0.8938 - val_loss: 0.3555 - val_acc: 0.8475\n",
      "Epoch 658/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3086 - acc: 0.8919 - val_loss: 0.3548 - val_acc: 0.8475\n",
      "Epoch 659/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3092 - acc: 0.8828 - val_loss: 0.3543 - val_acc: 0.8458\n",
      "Epoch 660/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3071 - acc: 0.8844 - val_loss: 0.3543 - val_acc: 0.8458\n",
      "Epoch 661/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3042 - acc: 0.8894 - val_loss: 0.3541 - val_acc: 0.8458\n",
      "Epoch 662/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2985 - acc: 0.8947 - val_loss: 0.3550 - val_acc: 0.8475\n",
      "Epoch 663/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3077 - acc: 0.8859 - val_loss: 0.3548 - val_acc: 0.8475\n",
      "Epoch 664/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3067 - acc: 0.8797 - val_loss: 0.3543 - val_acc: 0.8458\n",
      "Epoch 665/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2967 - acc: 0.8919 - val_loss: 0.3546 - val_acc: 0.8475\n",
      "Epoch 666/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3006 - acc: 0.8950 - val_loss: 0.3546 - val_acc: 0.8475\n",
      "Epoch 667/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3046 - acc: 0.8887 - val_loss: 0.3550 - val_acc: 0.8458\n",
      "Epoch 668/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3085 - acc: 0.8797 - val_loss: 0.3564 - val_acc: 0.8458\n",
      "Epoch 669/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3151 - acc: 0.8825 - val_loss: 0.3549 - val_acc: 0.8458\n",
      "Epoch 670/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3115 - acc: 0.8806 - val_loss: 0.3552 - val_acc: 0.8458\n",
      "Epoch 671/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3009 - acc: 0.8916 - val_loss: 0.3533 - val_acc: 0.8458\n",
      "Epoch 672/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3019 - acc: 0.8928 - val_loss: 0.3542 - val_acc: 0.8458\n",
      "Epoch 673/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3096 - acc: 0.8784 - val_loss: 0.3552 - val_acc: 0.8458\n",
      "Epoch 674/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3000 - acc: 0.8884 - val_loss: 0.3546 - val_acc: 0.8458\n",
      "Epoch 675/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3069 - acc: 0.8869 - val_loss: 0.3544 - val_acc: 0.8458\n",
      "Epoch 676/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3160 - acc: 0.8791 - val_loss: 0.3546 - val_acc: 0.8458\n",
      "Epoch 677/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3028 - acc: 0.8922 - val_loss: 0.3537 - val_acc: 0.8441\n",
      "Epoch 678/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3035 - acc: 0.8822 - val_loss: 0.3538 - val_acc: 0.8441\n",
      "Epoch 679/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2928 - acc: 0.8866 - val_loss: 0.3527 - val_acc: 0.8458\n",
      "Epoch 680/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2999 - acc: 0.8881 - val_loss: 0.3529 - val_acc: 0.8458\n",
      "Epoch 681/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3079 - acc: 0.8900 - val_loss: 0.3544 - val_acc: 0.8458\n",
      "Epoch 682/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3158 - acc: 0.8738 - val_loss: 0.3537 - val_acc: 0.8441\n",
      "Epoch 683/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3009 - acc: 0.8891 - val_loss: 0.3536 - val_acc: 0.8441\n",
      "Epoch 684/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3036 - acc: 0.8894 - val_loss: 0.3532 - val_acc: 0.8441\n",
      "Epoch 685/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3040 - acc: 0.8944 - val_loss: 0.3531 - val_acc: 0.8441\n",
      "Epoch 686/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3039 - acc: 0.8831 - val_loss: 0.3519 - val_acc: 0.8458\n",
      "Epoch 687/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3208 - acc: 0.8684 - val_loss: 0.3532 - val_acc: 0.8458\n",
      "Epoch 688/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2986 - acc: 0.8909 - val_loss: 0.3532 - val_acc: 0.8458\n",
      "Epoch 689/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3118 - acc: 0.8853 - val_loss: 0.3527 - val_acc: 0.8441\n",
      "Epoch 690/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3044 - acc: 0.8862 - val_loss: 0.3532 - val_acc: 0.8458\n",
      "Epoch 691/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3037 - acc: 0.8834 - val_loss: 0.3530 - val_acc: 0.8458\n",
      "Epoch 692/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3097 - acc: 0.8881 - val_loss: 0.3532 - val_acc: 0.8458\n",
      "Epoch 693/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3070 - acc: 0.8872 - val_loss: 0.3535 - val_acc: 0.8458\n",
      "Epoch 694/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3036 - acc: 0.8862 - val_loss: 0.3525 - val_acc: 0.8458\n",
      "Epoch 695/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2978 - acc: 0.8941 - val_loss: 0.3529 - val_acc: 0.8458\n",
      "Epoch 696/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3200 - acc: 0.8772 - val_loss: 0.3515 - val_acc: 0.8458\n",
      "Epoch 697/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.2893 - acc: 0.8934 - val_loss: 0.3528 - val_acc: 0.8458\n",
      "Epoch 698/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3060 - acc: 0.8831 - val_loss: 0.3516 - val_acc: 0.8458\n",
      "Epoch 699/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2989 - acc: 0.8894 - val_loss: 0.3525 - val_acc: 0.8458\n",
      "Epoch 700/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3176 - acc: 0.8747 - val_loss: 0.3520 - val_acc: 0.8458\n",
      "Epoch 701/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3032 - acc: 0.8906 - val_loss: 0.3521 - val_acc: 0.8458\n",
      "Epoch 702/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3001 - acc: 0.8869 - val_loss: 0.3505 - val_acc: 0.8458\n",
      "Epoch 703/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3097 - acc: 0.8837 - val_loss: 0.3516 - val_acc: 0.8458\n",
      "Epoch 704/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2974 - acc: 0.8884 - val_loss: 0.3521 - val_acc: 0.8458\n",
      "Epoch 705/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3033 - acc: 0.8909 - val_loss: 0.3520 - val_acc: 0.8458\n",
      "Epoch 706/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3036 - acc: 0.8850 - val_loss: 0.3504 - val_acc: 0.8458\n",
      "Epoch 707/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3079 - acc: 0.8853 - val_loss: 0.3511 - val_acc: 0.8458\n",
      "Epoch 708/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3104 - acc: 0.8853 - val_loss: 0.3516 - val_acc: 0.8458\n",
      "Epoch 709/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3021 - acc: 0.8900 - val_loss: 0.3516 - val_acc: 0.8458\n",
      "Epoch 710/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3030 - acc: 0.8825 - val_loss: 0.3509 - val_acc: 0.8441\n",
      "Epoch 711/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3089 - acc: 0.8844 - val_loss: 0.3502 - val_acc: 0.8458\n",
      "Epoch 712/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2955 - acc: 0.8909 - val_loss: 0.3503 - val_acc: 0.8441\n",
      "Epoch 713/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3015 - acc: 0.8947 - val_loss: 0.3508 - val_acc: 0.8458\n",
      "Epoch 714/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3048 - acc: 0.8800 - val_loss: 0.3500 - val_acc: 0.8441\n",
      "Epoch 715/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3088 - acc: 0.8869 - val_loss: 0.3505 - val_acc: 0.8441\n",
      "Epoch 716/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3052 - acc: 0.8856 - val_loss: 0.3506 - val_acc: 0.8441\n",
      "Epoch 717/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3029 - acc: 0.8831 - val_loss: 0.3507 - val_acc: 0.8458\n",
      "Epoch 718/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2967 - acc: 0.8916 - val_loss: 0.3508 - val_acc: 0.8458\n",
      "Epoch 719/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3126 - acc: 0.8809 - val_loss: 0.3506 - val_acc: 0.8458\n",
      "Epoch 720/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3009 - acc: 0.8875 - val_loss: 0.3507 - val_acc: 0.8458\n",
      "Epoch 721/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2997 - acc: 0.8925 - val_loss: 0.3505 - val_acc: 0.8458\n",
      "Epoch 722/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3071 - acc: 0.8828 - val_loss: 0.3496 - val_acc: 0.8441\n",
      "Epoch 723/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3017 - acc: 0.8894 - val_loss: 0.3493 - val_acc: 0.8441\n",
      "Epoch 724/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3025 - acc: 0.8878 - val_loss: 0.3498 - val_acc: 0.8441\n",
      "Epoch 725/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3066 - acc: 0.8847 - val_loss: 0.3496 - val_acc: 0.8441\n",
      "Epoch 726/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3109 - acc: 0.8819 - val_loss: 0.3494 - val_acc: 0.8441\n",
      "Epoch 727/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2988 - acc: 0.8831 - val_loss: 0.3492 - val_acc: 0.8441\n",
      "Epoch 728/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3039 - acc: 0.8887 - val_loss: 0.3497 - val_acc: 0.8458\n",
      "Epoch 729/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2947 - acc: 0.8969 - val_loss: 0.3495 - val_acc: 0.8441\n",
      "Epoch 730/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3115 - acc: 0.8738 - val_loss: 0.3491 - val_acc: 0.8441\n",
      "Epoch 731/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3122 - acc: 0.8803 - val_loss: 0.3494 - val_acc: 0.8441\n",
      "Epoch 732/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3064 - acc: 0.8844 - val_loss: 0.3503 - val_acc: 0.8475\n",
      "Epoch 733/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2965 - acc: 0.8903 - val_loss: 0.3508 - val_acc: 0.8475\n",
      "Epoch 734/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2993 - acc: 0.8919 - val_loss: 0.3491 - val_acc: 0.8441\n",
      "Epoch 735/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2966 - acc: 0.8913 - val_loss: 0.3486 - val_acc: 0.8441\n",
      "Epoch 736/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2978 - acc: 0.8903 - val_loss: 0.3503 - val_acc: 0.8475\n",
      "Epoch 737/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2934 - acc: 0.8916 - val_loss: 0.3488 - val_acc: 0.8441\n",
      "Epoch 738/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.2990 - acc: 0.8925 - val_loss: 0.3486 - val_acc: 0.8441\n",
      "Epoch 739/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3029 - acc: 0.8847 - val_loss: 0.3490 - val_acc: 0.8458\n",
      "Epoch 740/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2996 - acc: 0.8862 - val_loss: 0.3487 - val_acc: 0.8441\n",
      "Epoch 741/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2973 - acc: 0.8934 - val_loss: 0.3495 - val_acc: 0.8475\n",
      "Epoch 742/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2975 - acc: 0.8956 - val_loss: 0.3493 - val_acc: 0.8475\n",
      "Epoch 743/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3017 - acc: 0.8862 - val_loss: 0.3486 - val_acc: 0.8458\n",
      "Epoch 744/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3042 - acc: 0.8797 - val_loss: 0.3485 - val_acc: 0.8441\n",
      "Epoch 745/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2876 - acc: 0.9016 - val_loss: 0.3483 - val_acc: 0.8458\n",
      "Epoch 746/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2989 - acc: 0.8919 - val_loss: 0.3480 - val_acc: 0.8441\n",
      "Epoch 747/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3027 - acc: 0.8819 - val_loss: 0.3471 - val_acc: 0.8441\n",
      "Epoch 748/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2980 - acc: 0.8859 - val_loss: 0.3470 - val_acc: 0.8441\n",
      "Epoch 749/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2905 - acc: 0.8991 - val_loss: 0.3482 - val_acc: 0.8458\n",
      "Epoch 750/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2973 - acc: 0.8862 - val_loss: 0.3484 - val_acc: 0.8475\n",
      "Epoch 751/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2930 - acc: 0.8853 - val_loss: 0.3484 - val_acc: 0.8475\n",
      "Epoch 752/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2904 - acc: 0.8984 - val_loss: 0.3484 - val_acc: 0.8475\n",
      "Epoch 753/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3010 - acc: 0.8850 - val_loss: 0.3489 - val_acc: 0.8475\n",
      "Epoch 754/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3027 - acc: 0.8822 - val_loss: 0.3490 - val_acc: 0.8475\n",
      "Epoch 755/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2947 - acc: 0.8956 - val_loss: 0.3475 - val_acc: 0.8441\n",
      "Epoch 756/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2862 - acc: 0.8966 - val_loss: 0.3484 - val_acc: 0.8475\n",
      "Epoch 757/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2958 - acc: 0.8881 - val_loss: 0.3480 - val_acc: 0.8475\n",
      "Epoch 758/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2966 - acc: 0.8922 - val_loss: 0.3473 - val_acc: 0.8458\n",
      "Epoch 759/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3006 - acc: 0.8903 - val_loss: 0.3465 - val_acc: 0.8458\n",
      "Epoch 760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3068 - acc: 0.8825 - val_loss: 0.3464 - val_acc: 0.8441\n",
      "Epoch 761/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2894 - acc: 0.9000 - val_loss: 0.3468 - val_acc: 0.8441\n",
      "Epoch 762/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3012 - acc: 0.8884 - val_loss: 0.3463 - val_acc: 0.8441\n",
      "Epoch 763/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2956 - acc: 0.8919 - val_loss: 0.3467 - val_acc: 0.8458\n",
      "Epoch 764/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2970 - acc: 0.8897 - val_loss: 0.3455 - val_acc: 0.8475\n",
      "Epoch 765/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2894 - acc: 0.8941 - val_loss: 0.3466 - val_acc: 0.8458\n",
      "Epoch 766/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2833 - acc: 0.9025 - val_loss: 0.3467 - val_acc: 0.8458\n",
      "Epoch 767/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3030 - acc: 0.8869 - val_loss: 0.3470 - val_acc: 0.8458\n",
      "Epoch 768/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2956 - acc: 0.8891 - val_loss: 0.3464 - val_acc: 0.8458\n",
      "Epoch 769/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2960 - acc: 0.8866 - val_loss: 0.3463 - val_acc: 0.8458\n",
      "Epoch 770/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2923 - acc: 0.8934 - val_loss: 0.3460 - val_acc: 0.8458\n",
      "Epoch 771/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2992 - acc: 0.8928 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 772/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2990 - acc: 0.8841 - val_loss: 0.3471 - val_acc: 0.8458\n",
      "Epoch 773/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2888 - acc: 0.8887 - val_loss: 0.3458 - val_acc: 0.8458\n",
      "Epoch 774/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2875 - acc: 0.8981 - val_loss: 0.3460 - val_acc: 0.8458\n",
      "Epoch 775/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3010 - acc: 0.8925 - val_loss: 0.3459 - val_acc: 0.8458\n",
      "Epoch 776/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2931 - acc: 0.8903 - val_loss: 0.3464 - val_acc: 0.8458\n",
      "Epoch 777/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2901 - acc: 0.8994 - val_loss: 0.3460 - val_acc: 0.8458\n",
      "Epoch 778/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3082 - acc: 0.8812 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 779/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3005 - acc: 0.8872 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 780/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2897 - acc: 0.8941 - val_loss: 0.3461 - val_acc: 0.8458\n",
      "Epoch 781/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.3014 - acc: 0.8831 - val_loss: 0.3454 - val_acc: 0.8458\n",
      "Epoch 782/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.3006 - acc: 0.8834 - val_loss: 0.3457 - val_acc: 0.8458\n",
      "Epoch 783/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2916 - acc: 0.8972 - val_loss: 0.3451 - val_acc: 0.8458\n",
      "Epoch 784/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2930 - acc: 0.8950 - val_loss: 0.3455 - val_acc: 0.8458\n",
      "Epoch 785/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2931 - acc: 0.8975 - val_loss: 0.3453 - val_acc: 0.8458\n",
      "Epoch 786/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2908 - acc: 0.8906 - val_loss: 0.3447 - val_acc: 0.8492\n",
      "Epoch 787/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2896 - acc: 0.8947 - val_loss: 0.3450 - val_acc: 0.8475\n",
      "Epoch 788/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2989 - acc: 0.8941 - val_loss: 0.3452 - val_acc: 0.8458\n",
      "Epoch 789/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2899 - acc: 0.9009 - val_loss: 0.3459 - val_acc: 0.8458\n",
      "Epoch 790/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.2948 - acc: 0.8913 - val_loss: 0.3453 - val_acc: 0.8458\n",
      "Epoch 791/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2872 - acc: 0.8938 - val_loss: 0.3454 - val_acc: 0.8458\n",
      "Epoch 792/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2969 - acc: 0.8944 - val_loss: 0.3449 - val_acc: 0.8458\n",
      "Epoch 793/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2888 - acc: 0.8969 - val_loss: 0.3455 - val_acc: 0.8458\n",
      "Epoch 794/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2941 - acc: 0.8938 - val_loss: 0.3448 - val_acc: 0.8475\n",
      "Epoch 795/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2893 - acc: 0.9031 - val_loss: 0.3446 - val_acc: 0.8475\n",
      "Epoch 796/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2966 - acc: 0.8916 - val_loss: 0.3449 - val_acc: 0.8458\n",
      "Epoch 797/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2868 - acc: 0.8975 - val_loss: 0.3451 - val_acc: 0.8475\n",
      "Epoch 798/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2909 - acc: 0.8938 - val_loss: 0.3437 - val_acc: 0.8475\n",
      "Epoch 799/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2806 - acc: 0.9069 - val_loss: 0.3447 - val_acc: 0.8458\n",
      "Epoch 800/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2924 - acc: 0.9006 - val_loss: 0.3440 - val_acc: 0.8475\n",
      "Epoch 801/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2947 - acc: 0.8959 - val_loss: 0.3448 - val_acc: 0.8475\n",
      "Epoch 802/2000\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.2978 - acc: 0.8903 - val_loss: 0.3444 - val_acc: 0.8458\n",
      "Epoch 803/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2889 - acc: 0.8969 - val_loss: 0.3445 - val_acc: 0.8458\n",
      "Epoch 804/2000\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.2925 - acc: 0.8881 - val_loss: 0.3441 - val_acc: 0.8458\n",
      "Epoch 805/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2868 - acc: 0.8997 - val_loss: 0.3448 - val_acc: 0.8475\n",
      "Epoch 806/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2998 - acc: 0.8837 - val_loss: 0.3446 - val_acc: 0.8475\n",
      "Epoch 807/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2951 - acc: 0.8953 - val_loss: 0.3445 - val_acc: 0.8475\n",
      "Epoch 808/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2973 - acc: 0.8941 - val_loss: 0.3449 - val_acc: 0.8475\n",
      "Epoch 809/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2923 - acc: 0.8897 - val_loss: 0.3438 - val_acc: 0.8458\n",
      "Epoch 810/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2973 - acc: 0.8900 - val_loss: 0.3448 - val_acc: 0.8475\n",
      "Epoch 811/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2974 - acc: 0.8909 - val_loss: 0.3442 - val_acc: 0.8475\n",
      "Epoch 812/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2799 - acc: 0.9031 - val_loss: 0.3434 - val_acc: 0.8458\n",
      "Epoch 813/2000\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.2920 - acc: 0.8922 - val_loss: 0.3434 - val_acc: 0.8458\n",
      "Epoch 814/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2882 - acc: 0.8947 - val_loss: 0.3437 - val_acc: 0.8458\n",
      "Epoch 815/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2847 - acc: 0.8984 - val_loss: 0.3434 - val_acc: 0.8458\n",
      "Epoch 816/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2852 - acc: 0.8994 - val_loss: 0.3426 - val_acc: 0.8492\n",
      "Epoch 817/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2917 - acc: 0.8922 - val_loss: 0.3431 - val_acc: 0.8492\n",
      "Epoch 818/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2970 - acc: 0.8916 - val_loss: 0.3441 - val_acc: 0.8458\n",
      "Epoch 819/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2963 - acc: 0.8909 - val_loss: 0.3445 - val_acc: 0.8475\n",
      "Epoch 820/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2863 - acc: 0.9006 - val_loss: 0.3439 - val_acc: 0.8458\n",
      "Epoch 821/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2959 - acc: 0.8916 - val_loss: 0.3438 - val_acc: 0.8458\n",
      "Epoch 822/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2950 - acc: 0.8875 - val_loss: 0.3442 - val_acc: 0.8475\n",
      "Epoch 823/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2967 - acc: 0.8884 - val_loss: 0.3445 - val_acc: 0.8475\n",
      "Epoch 824/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2871 - acc: 0.8941 - val_loss: 0.3440 - val_acc: 0.8475\n",
      "Epoch 825/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2792 - acc: 0.9034 - val_loss: 0.3433 - val_acc: 0.8458\n",
      "Epoch 826/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2862 - acc: 0.8962 - val_loss: 0.3436 - val_acc: 0.8458\n",
      "Epoch 827/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2938 - acc: 0.8881 - val_loss: 0.3440 - val_acc: 0.8458\n",
      "Epoch 828/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2809 - acc: 0.9016 - val_loss: 0.3435 - val_acc: 0.8458\n",
      "Epoch 829/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2945 - acc: 0.8988 - val_loss: 0.3432 - val_acc: 0.8475\n",
      "Epoch 830/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3011 - acc: 0.8903 - val_loss: 0.3435 - val_acc: 0.8458\n",
      "Epoch 831/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2943 - acc: 0.8869 - val_loss: 0.3439 - val_acc: 0.8475\n",
      "Epoch 832/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2889 - acc: 0.8919 - val_loss: 0.3436 - val_acc: 0.8458\n",
      "Epoch 833/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2896 - acc: 0.8906 - val_loss: 0.3430 - val_acc: 0.8475\n",
      "Epoch 834/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2900 - acc: 0.8906 - val_loss: 0.3431 - val_acc: 0.8458\n",
      "Epoch 835/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2855 - acc: 0.8994 - val_loss: 0.3427 - val_acc: 0.8475\n",
      "Epoch 836/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2895 - acc: 0.8913 - val_loss: 0.3425 - val_acc: 0.8475\n",
      "Epoch 837/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2829 - acc: 0.8947 - val_loss: 0.3418 - val_acc: 0.8492\n",
      "Epoch 838/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2882 - acc: 0.8916 - val_loss: 0.3419 - val_acc: 0.8492\n",
      "Epoch 839/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2928 - acc: 0.8909 - val_loss: 0.3420 - val_acc: 0.8492\n",
      "Epoch 840/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2941 - acc: 0.8884 - val_loss: 0.3409 - val_acc: 0.8508\n",
      "Epoch 841/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2837 - acc: 0.8997 - val_loss: 0.3411 - val_acc: 0.8492\n",
      "Epoch 842/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3019 - acc: 0.8844 - val_loss: 0.3411 - val_acc: 0.8508\n",
      "Epoch 843/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2888 - acc: 0.8969 - val_loss: 0.3419 - val_acc: 0.8492\n",
      "Epoch 844/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2888 - acc: 0.8956 - val_loss: 0.3418 - val_acc: 0.8492\n",
      "Epoch 845/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2856 - acc: 0.8994 - val_loss: 0.3414 - val_acc: 0.8492\n",
      "Epoch 846/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.3034 - acc: 0.8872 - val_loss: 0.3424 - val_acc: 0.8458\n",
      "Epoch 847/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2788 - acc: 0.9053 - val_loss: 0.3420 - val_acc: 0.8475\n",
      "Epoch 848/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2891 - acc: 0.8913 - val_loss: 0.3422 - val_acc: 0.8458\n",
      "Epoch 849/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2906 - acc: 0.8991 - val_loss: 0.3419 - val_acc: 0.8475\n",
      "Epoch 850/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2850 - acc: 0.8956 - val_loss: 0.3414 - val_acc: 0.8492\n",
      "Epoch 851/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2822 - acc: 0.9025 - val_loss: 0.3417 - val_acc: 0.8475\n",
      "Epoch 852/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2827 - acc: 0.9038 - val_loss: 0.3414 - val_acc: 0.8492\n",
      "Epoch 853/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2830 - acc: 0.8959 - val_loss: 0.3413 - val_acc: 0.8492\n",
      "Epoch 854/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2884 - acc: 0.8966 - val_loss: 0.3413 - val_acc: 0.8492\n",
      "Epoch 855/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2935 - acc: 0.8887 - val_loss: 0.3420 - val_acc: 0.8475\n",
      "Epoch 856/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2884 - acc: 0.8966 - val_loss: 0.3421 - val_acc: 0.8475\n",
      "Epoch 857/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2897 - acc: 0.8928 - val_loss: 0.3419 - val_acc: 0.8492\n",
      "Epoch 858/2000\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2839 - acc: 0.9025 - val_loss: 0.3418 - val_acc: 0.8492\n",
      "Epoch 859/2000\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.2949 - acc: 0.8906 - val_loss: 0.3420 - val_acc: 0.8475\n",
      "Epoch 860/2000\n",
      "200/200 [==============================] - 25s 127ms/step - loss: 0.2872 - acc: 0.9034 - val_loss: 0.3420 - val_acc: 0.8475\n",
      "Epoch 00860: early stopping\n",
      "Model saved.\n",
      "Test loss: 0.3419984745777259\n",
      "Test accuracy: 0.8474576200469065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  1 =>  plastic\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    # Load all images\n",
    "    all_images_array = np.load('all_images_array.npy')\n",
    "\n",
    "    # load the the class labels\n",
    "    all_labels = np.load('all_labels.npy')\n",
    "\n",
    "    # Split the dataset into train and test sets, with percentage of splitting = 70 / 30 respectively\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_images_array, all_labels, test_size=0.30, shuffle=True, random_state=78)\n",
    "\n",
    "    # Data normalization to convert features to the same scale\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    #x_train /= 255\n",
    "    #x_test /= 255\n",
    "\n",
    "    x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "    x_test  = (x_test - np.mean(x_test)) / np.std(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # convert class vectors to One-hot encoding\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    train(x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    prediction, label = test(x_test)\n",
    "    \n",
    "    print('The prediction of this object is:', prediction, '=> ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workers = 8\n",
    "#step_per_epoch 100:\n",
    "#Test loss: 0.34983771067049546\n",
    "#Test accuracy: 0.8220338942640919\n",
    "\n",
    "#step_per_epoch 200: epoch=>72\n",
    "#Test loss: 0.28055439813662386\n",
    "#Test accuracy: 0.8932203276682709\n",
    "\n",
    "#step_per_epoch 400: epoch=>12 continous\n",
    "#Test loss: 0.2784507023328442\n",
    "#Test accuracy: 0.8949152453471039\n",
    "\n",
    "#step_per_epoch 800: epoch=>9 continous\n",
    "#Test loss: 0.2843580770669347\n",
    "#Test accuracy: 0.9050847372766269\n",
    "\n",
    "#==========================================\n",
    "#Workers = 32\n",
    "#step_per_epoch 100:  epoch=>10 continous\n",
    "#Test loss: 0.2690500178200714\n",
    "#Test accuracy: 0.9033898216182903\n",
    "\n",
    "#step_per_epoch 200:  epoch=>18 continous\n",
    "#Test loss: 0.2979729557252031\n",
    "#Test accuracy: 0.9050847372766269\n",
    "\n",
    "#step_per_epoch 400: epoch=>10 continous\n",
    "#Test loss: 0.2838988147234007\n",
    "#Test accuracy: 0.9067796549554599\n",
    "\n",
    "#step_per_epoch 400: epoch=>6 continous\n",
    "#Test loss: 0.2930123057468968\n",
    "#Test accuracy: 0.9101694842516366\n",
    "\n",
    "#having nbr of worker=32 and step_per_epoch=800 makes the memory overwhelms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 Tensorflow Keras",
   "language": "python",
   "name": "py35-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
